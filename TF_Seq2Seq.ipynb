{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcS1T5K3bYDu+sIzNGEDRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlavee/slt-cs230/blob/main/TF_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvC2uwa8jUP4"
      },
      "source": [
        "# Seq2Seq for Translation\r\n",
        "\r\n",
        "This colab performs simple data processing and set up Seq2Seq for Translation using Datasets for SLT project (CS230).\r\n",
        "\r\n",
        "Code is adapted from [Seq2Seq for Translation Tutorial](https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt).\r\n",
        "\r\n",
        "## Data\r\n",
        "The easiest way to get the data for this colab is to download `data/` folder from [Github](https://github.com/nlavee/slt-cs230/tree/main/data), and upload them to the env of colab. Note that each time the colab instance is down, all data will be wiped, so you'll have to reupload them. \r\n",
        "\r\n",
        "*(Another way to do this is through GitHub API, which unfortunately prevents reading files larger than 1MB).*\r\n",
        "\r\n",
        "\r\n",
        "anhvu.nguyenlam@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6PYtEOg-DdE"
      },
      "source": [
        "## **TODO for the team:**\r\n",
        "\r\n",
        "[For next week]\r\n",
        "1. Read through original [Github page](https://github.com/kayoyin/transformer-slt) to understand pytorch implementation. Priorities: \r\n",
        "    0. [Data preprocessing](https://github.com/kayoyin/transformer-slt#data-processing). Whether OpenNMT has a TF counterpart? [All will check to see what this do?]\r\n",
        "    1. rnn with attention model with encoder / decoder. [Ben will check this part] \r\n",
        "    2. transformer. [El will check on this part]\r\n",
        "2. Understand this colab to see how much we've gotten from tensorflow implementation.\r\n",
        "   * Improve data ingestion for this colab [Vu will check on this]\r\n",
        "   * Define metrics that we care about in this colab as well.  [Vu will check on this]\r\n",
        "\r\n",
        "[After next week]\r\n",
        "3. Try to replicate the same architecture in pytorch over to tf. Priorities: 1) rnn with attention 2) transformer.\r\n",
        "4. Look into making the model run with fewer resources available\r\n",
        "\r\n",
        "[Interim]\r\n",
        "5. Look into SLR models that we can use to plug into image --> gloss to get input for this particular model. Do this when we can :)\r\n",
        "\r\n",
        "\r\n",
        "## What we want to do with the project?\r\n",
        "* Improve models, add features, technique (regularization, etc)\r\n",
        "* Quantization of models to run on edge devices\r\n",
        "* (Think about this...)\r\n",
        "\r\n",
        "## Midterms prep:\r\n",
        "* Let's do winter 2020 together next week\r\n",
        "* Do the previous years by yourself first to prep to that 2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlx5EMUiz9dX",
        "outputId": "ab544aad-d4b6-4d40-b8f4-f2d142bb3a55"
      },
      "source": [
        "pip install tensorflow-addons==0.11.2"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.11.2 in /usr/local/lib/python3.6/dist-packages (0.11.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.2) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNdG5vqQPc8b",
        "cellView": "form"
      },
      "source": [
        "#@title Import / Setup\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "from _collections import defaultdict\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "import unicodedata\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import io\r\n",
        "import time"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AFH8dKecby8",
        "cellView": "form"
      },
      "source": [
        "#@title Looking at the Train ASLG EN dataset.\r\n",
        "\r\n",
        "train_en_dataset_path = \"aslg.train.en\" #@param {type: \"string\", is_template: true}\r\n",
        "train_gloss_dataset_path = \"aslg.train.gloss.asl\" #@param {type: \"string\", is_template: true}\r\n",
        "# f = open(train_dataset_path, \"r\")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECspLHRS1E5p"
      },
      "source": [
        "class NMTDataset:\r\n",
        "  def __init__(self, problem_type=\"gloss-en\"):\r\n",
        "    self.problem_type = problem_type\r\n",
        "    self.inp_lang_tokenizer = None\r\n",
        "    self.targ_lang_tokenizer = None\r\n",
        "\r\n",
        "  def unicode_to_ascii(self, s):\r\n",
        "    return ''.join (c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c))\r\n",
        "  \r\n",
        "  ## 1) Add a start and end token to each sentence.\r\n",
        "  ## 2) Clean the sentences by removing special characters.\r\n",
        "  def preprocess_sentence(self, w):\r\n",
        "    w = self.unicode_to_ascii(w.lower().strip())\r\n",
        "\r\n",
        "    # creating a space between a word and the punctuation following it\r\n",
        "    # e.g.: \"he is a boy.\" => \"he is a boy .\"\r\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\r\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\r\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "\r\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"-\")\r\n",
        "    w = re.sub(r\"[^a-zA-Z?.!\\-,¿]+\", \" \", w)\r\n",
        "\r\n",
        "    w = w.strip()\r\n",
        "\r\n",
        "    # adding a start and an end token to the sentence\r\n",
        "    # so that the model know when to start and stop predicting.\r\n",
        "    w = '<start> ' + w + ' <end>'\r\n",
        "    # print(f\"Processed Sentence: {w}\")\r\n",
        "    return w\r\n",
        "  \r\n",
        "  def create_dataset(self, paths, num_examples):\r\n",
        "    (train_en_set_path, train_gloss_set_path) = paths\r\n",
        "\r\n",
        "    train_en_lines = io.open(train_en_set_path, encoding='UTF-8').read().strip().split('\\n')\r\n",
        "    train_gloss_lines = io.open(train_gloss_set_path, encoding='UTF-8').read().strip().split('\\n')\r\n",
        "    \r\n",
        "    word_pairs = []\r\n",
        "    for i in range(0, num_examples):\r\n",
        "      inp = train_gloss_lines[i]\r\n",
        "      targ = train_en_lines[i]\r\n",
        "      # print(f\"Input: {inp} - Target: {targ}\")\r\n",
        "      word_pairs.append(\r\n",
        "          [self.preprocess_sentence(inp), \r\n",
        "           self.preprocess_sentence(targ)])\r\n",
        "      \r\n",
        "    return zip(*word_pairs)\r\n",
        "  \r\n",
        "  ## 3) Create a vocabulary with word index (mapping from word -> id) and reverse word index (mapping from id -> word)\r\n",
        "  ## 4) Pad each sentence to a maximum length.\r\n",
        "  def tokenize(self, lang):\r\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>')\r\n",
        "    lang_tokenizer.fit_on_texts(lang)\r\n",
        "\r\n",
        "    ## tf.keras.preprocessing.text.Tokenizer.texts_to_sequences converts string (w1, w2, w3, ......, wn) \r\n",
        "    ## to a list of correspoding integer ids of words (id_w1, id_w2, id_w3, ...., id_wn)\r\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang) \r\n",
        "    print(f\"Tensor of sequences from texts: {tensor}\")\r\n",
        "\r\n",
        "    ## tf.keras.preprocessing.sequence.pad_sequences takes argument a list of integer id sequences\r\n",
        "    ## and pads the sequences (at the end) to match the longest sequences in the given input.\r\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\r\n",
        "\r\n",
        "    return tensor, lang_tokenizer\r\n",
        "  \r\n",
        "  def load_dataset(self, paths, num_examples=None):\r\n",
        "    # creating cleaned input, output pairs.\r\n",
        "    targ_lang, inp_lang = self.create_dataset(paths, num_examples)\r\n",
        "\r\n",
        "    input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang)\r\n",
        "    target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang)\r\n",
        "\r\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\r\n",
        "  \r\n",
        "  def call(self, num_examples, BUFFER_SIZE, BATCH_SIZE):    \r\n",
        "    input_tensor, target_tensor, self.inp_lang_tokenizer, self.targ_lang_tokenizer = self.load_dataset(\r\n",
        "        (train_en_dataset_path, train_gloss_dataset_path), \r\n",
        "        num_examples)\r\n",
        "\r\n",
        "    # Can skip this test since we have dedicated test set.\r\n",
        "    input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\r\n",
        "        input_tensor, \r\n",
        "        target_tensor, \r\n",
        "        test_size = 0.2)\r\n",
        "\r\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\r\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "\r\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\r\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder = True)\r\n",
        "\r\n",
        "    return train_dataset, val_dataset, self.inp_lang_tokenizer, self.targ_lang_tokenizer\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvrk3PNc-0KJ",
        "outputId": "f5d19068-6b7b-4aef-8d43-5a0dd3c4ca7b"
      },
      "source": [
        "BUFFER_SIZE = 32000 #@param {is_template:true}\r\n",
        "BATCH_SIZE = 64 #@param {is_template:true}\r\n",
        "# Let's limit the #training examples for faster training\r\n",
        "num_examples = 1024 #@param {is_template:true}\r\n",
        "\r\n",
        "dataset_creator = NMTDataset('gloss-en')\r\n",
        "train_dataset, val_dataset, inp_lang, targ_lang = dataset_creator.call(num_examples, BUFFER_SIZE, BATCH_SIZE)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor of sequences from texts: [[2, 23, 4, 24, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 147, 4, 148, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 30, 40, 11, 78, 79, 55, 6, 5, 3], [2, 101, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 63, 83, 19, 24, 56, 71, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 210, 4, 267, 178, 4, 7, 25, 24, 108, 13, 268, 211, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 210, 4, 407, 4, 7, 25, 24, 108, 13, 268, 211, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 108, 13, 55, 122, 6, 5, 3], [2, 7, 10, 16, 35, 14, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 18, 8, 15, 8, 11, 43, 13, 26, 65, 14, 269, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 149, 4, 408, 270, 7, 409, 4, 7, 410, 212, 411, 412, 413, 4, 414, 6, 5, 3], [2, 271, 41, 7, 213, 6, 5, 3], [2, 23, 4, 44, 9, 3], [2, 272, 4, 7, 415, 51, 84, 46, 9, 3], [2, 273, 4, 274, 275, 276, 277, 11, 278, 19, 7, 214, 179, 21, 7, 73, 9, 3], [2, 92, 215, 20, 279, 280, 150, 281, 282, 9, 3], [2, 416, 11, 417, 283, 284, 19, 418, 285, 9, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 93, 13, 216, 4, 109, 88, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 7, 59, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 110, 8, 3], [2, 7, 10, 16, 34, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 93, 13, 7, 124, 4, 109, 88, 6, 5, 3], [2, 217, 20, 44, 180, 41, 7, 181, 4, 178, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 63, 83, 19, 24, 56, 71, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 31, 6, 5, 3], [2, 217, 20, 109, 44, 9, 6, 5, 3], [2, 26, 65, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 182, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 90, 4, 286, 151, 419, 420, 9, 3], [2, 28, 4, 125, 103, 152, 421, 20, 7, 422, 126, 4, 287, 4, 7, 423, 9, 3], [2, 51, 424, 46, 19, 218, 11, 425, 80, 9, 3], [2, 426, 288, 21, 153, 80, 427, 9, 3], [2, 127, 154, 111, 112, 9, 3], [2, 51, 428, 97, 84, 9, 3], [2, 429, 430, 21, 128, 113, 431, 432, 289, 433, 11, 434, 435, 9, 3], [2, 7, 25, 436, 437, 438, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 439, 440, 19, 18, 219, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 101, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 290, 4, 441, 9, 3], [2, 291, 13, 442, 155, 21, 7, 25, 73, 443, 9, 3], [2, 292, 444, 9, 3], [2, 293, 21, 445, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 26, 65, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 7, 5, 4, 7, 29, 10, 294, 295, 8, 3], [2, 271, 41, 7, 213, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 183, 184, 220, 13, 71, 221, 6, 5, 3], [2, 296, 50, 446, 220, 13, 71, 221, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 182, 3], [2, 49, 4, 7, 10, 3], [2, 447, 114, 156, 13, 297, 9, 3], [2, 185, 4, 448, 4, 449, 450, 298, 9, 3], [2, 451, 452, 9, 3], [2, 7, 222, 4, 453, 12, 112, 19, 7, 299, 25, 454, 13, 129, 9, 3], [2, 455, 456, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 26, 65, 130, 3], [2, 7, 22, 157, 158, 26, 65, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 31, 13, 22, 159, 59, 6, 5, 3], [2, 33, 4, 10, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 457, 82, 9, 3], [2, 111, 156, 13, 458, 223, 9, 3], [2, 300, 186, 9, 3], [2, 301, 131, 302, 303, 50, 459, 11, 460, 9, 3], [2, 51, 224, 461, 46, 9, 3], [2, 60, 187, 4, 7, 225, 21, 462, 9, 3], [2, 226, 98, 463, 13, 9, 3], [2, 304, 283, 12, 9, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 464, 160, 7, 465, 466, 11, 467, 4, 7, 468, 469, 9, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 59, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 35, 8, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 101, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 23, 4, 227, 305, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 306, 11, 307, 308, 4, 161, 47, 108, 13, 55, 122, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 470, 4, 7, 59, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 110, 8, 3], [2, 49, 4, 7, 59, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 471, 8, 3], [2, 27, 32, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 309, 4, 472, 41, 7, 473, 50, 228, 132, 9, 3], [2, 474, 4, 229, 51, 112, 19, 475, 476, 9, 3], [2, 477, 310, 4, 478, 11, 311, 4, 479, 9, 3], [2, 480, 230, 481, 9, 3], [2, 128, 113, 482, 483, 312, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 8, 306, 11, 307, 308, 4, 7, 161, 47, 9, 3], [2, 313, 4, 7, 484, 4, 314, 315, 485, 486, 91, 487, 9, 3], [2, 488, 4, 7, 489, 56, 490, 316, 317, 133, 9, 3], [2, 230, 162, 4, 491, 492, 9, 3], [2, 51, 493, 163, 129, 46, 9, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 217, 20, 161, 47, 180, 41, 7, 181, 4, 178, 6, 5, 3], [2, 494, 318, 30, 319, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 211, 20, 161, 47, 9, 3], [2, 73, 63, 19, 7, 495, 4, 128, 113, 134, 496, 9, 3], [2, 497, 498, 9, 3], [2, 499, 4, 500, 118, 320, 321, 501, 46, 9, 3], [2, 119, 98, 502, 11, 322, 11, 226, 503, 9, 3], [2, 504, 505, 11, 153, 80, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 164, 19, 165, 4, 166, 4, 85, 82, 50, 167, 11, 7, 39, 4, 92, 188, 3], [2, 506, 9, 3], [2, 323, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 63, 83, 19, 24, 56, 71, 6, 5, 3], [2, 31, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 18, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 23, 4, 227, 305, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 73, 324, 21, 7, 507, 311, 4, 7, 25, 508, 231, 9, 3], [2, 93, 13, 124, 4, 7, 88, 4, 325, 232, 9, 3], [2, 509, 152, 7, 150, 4, 510, 233, 9, 3], [2, 511, 512, 11, 114, 513, 4, 514, 9, 3], [2, 515, 14, 326, 516, 9, 3], [2, 7, 189, 4, 517, 11, 7, 518, 4, 7, 118, 9, 3], [2, 7, 189, 4, 7, 25, 168, 56, 519, 234, 9, 3], [2, 189, 4, 520, 326, 21, 190, 9, 3], [2, 7, 521, 4, 235, 219, 233, 21, 7, 522, 9, 3], [2, 77, 81, 7, 9, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 23, 4, 161, 47, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 63, 83, 19, 24, 56, 71, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 135, 4, 114, 236, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 18, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 51, 303, 46, 19, 57, 191, 4, 163, 162, 9, 3], [2, 12, 169, 3], [2, 523, 524, 13, 525, 270, 136, 11, 137, 4, 526, 527, 528, 9, 3], [2, 12, 529, 530, 531, 3], [2, 8, 216, 4, 7, 88, 4, 532, 192, 533, 9, 3], [2, 12, 327, 3], [2, 58, 132, 534, 50, 222, 4, 535, 9, 3], [2, 12, 138, 3], [2, 58, 132, 536, 50, 222, 4, 537, 9, 3], [2, 12, 138, 3], [2, 12, 138, 3], [2, 58, 132, 538, 50, 25, 539, 9, 3], [2, 12, 138, 3], [2, 58, 132, 540, 170, 50, 25, 328, 90, 541, 9, 3], [2, 12, 138, 3], [2, 58, 193, 50, 193, 50, 193, 11, 193, 542, 9, 3], [2, 12, 543, 3], [2, 58, 25, 171, 13, 7, 153, 4, 544, 237, 9, 3], [2, 12, 68, 3], [2, 58, 25, 329, 13, 7, 545, 4, 546, 11, 547, 548, 9, 3], [2, 12, 68, 3], [2, 58, 25, 330, 171, 19, 331, 11, 332, 9, 3], [2, 12, 68, 3], [2, 58, 25, 330, 171, 13, 549, 11, 550, 551, 9, 3], [2, 12, 68, 3], [2, 58, 25, 238, 194, 9, 3], [2, 12, 68, 3], [2, 58, 25, 194, 13, 139, 11, 134, 14, 333, 9, 3], [2, 12, 68, 3], [2, 58, 334, 171, 13, 7, 552, 4, 7, 25, 168, 9, 3], [2, 12, 68, 3], [2, 58, 25, 194, 13, 7, 553, 4, 554, 140, 9, 3], [2, 12, 68, 3], [2, 58, 555, 9, 3], [2, 12, 68, 3], [2, 58, 25, 237, 329, 9, 3], [2, 12, 68, 3], [2, 58, 25, 316, 139, 194, 9, 3], [2, 12, 68, 3], [2, 12, 68, 3], [2, 58, 25, 195, 139, 556, 9, 3], [2, 12, 68, 3], [2, 58, 25, 171, 13, 335, 336, 11, 196, 9, 3], [2, 12, 68, 3], [2, 58, 132, 557, 50, 149, 4, 7, 558, 9, 3], [2, 12, 138, 3], [2, 12, 68, 3], [2, 197, 559, 560, 561, 7, 118, 11, 21, 7, 562, 223, 9, 3], [2, 12, 563, 3], [2, 77, 81, 7, 9, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 564, 7, 565, 4, 18, 566, 567, 21, 190, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 198, 18, 568, 569, 570, 12, 3], [2, 571, 572, 130, 20, 573, 11, 20, 93, 7, 574, 3], [2, 239, 46, 19, 7, 337, 4, 18, 25, 60, 338, 240, 9, 3], [2, 575, 12, 3], [2, 576, 7, 9, 50, 7, 577, 578, 579, 3], [2, 339, 46, 19, 18, 239, 580, 241, 172, 21, 7, 581, 582, 9, 3], [2, 583, 12, 3], [2, 26, 65, 130, 3], [2, 310, 11, 312, 4, 584, 585, 9, 3], [2, 586, 120, 3], [2, 26, 65, 130, 3], [2, 587, 588, 196, 9, 3], [2, 589, 12, 3], [2, 590, 591, 11, 592, 593, 9, 3], [2, 242, 594, 595, 12, 3], [2, 243, 149, 19, 183, 184, 9, 3], [2, 180, 13, 18, 173, 3], [2, 596, 597, 13, 598, 4, 340, 174, 9, 3], [2, 199, 341, 599, 12, 3], [2, 239, 46, 19, 7, 337, 4, 18, 25, 60, 338, 240, 9, 3], [2, 54, 13, 18, 48, 3], [2, 600, 131, 19, 7, 200, 201, 4, 322, 234, 9, 3], [2, 601, 12, 3], [2, 26, 65, 130, 3], [2, 36, 20, 37, 244, 29, 67, 6, 5, 3], [2, 7, 10, 16, 35, 14, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 18, 8, 15, 8, 11, 43, 14, 8, 269, 3], [2, 602, 66, 7, 90, 4, 134, 11, 139, 4, 342, 603, 11, 604, 605, 245, 284, 9, 3], [2, 606, 12, 3], [2, 607, 13, 57, 608, 140, 9, 3], [2, 609, 12, 3], [2, 60, 97, 98, 119, 610, 611, 9, 3], [2, 612, 12, 3], [2, 246, 4, 613, 293, 21, 7, 25, 168, 9, 3], [2, 614, 198, 18, 12, 3], [2, 615, 155, 19, 616, 617, 618, 9, 3], [2, 619, 12, 3], [2, 620, 113, 621, 622, 9, 3], [2, 623, 12, 3], [2, 185, 11, 200, 624, 4, 97, 234, 9, 3], [2, 625, 12, 3], [2, 247, 9, 3], [2, 54, 13, 18, 48, 3], [2, 248, 626, 21, 7, 627, 9, 3], [2, 628, 12, 3], [2, 77, 81, 26, 65, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 31, 6, 5, 3], [2, 164, 19, 165, 4, 166, 4, 85, 82, 50, 167, 11, 7, 39, 4, 92, 3], [2, 629, 630, 4, 631, 21, 224, 9, 3], [2, 121, 54, 13, 18, 48, 202, 170, 3], [2, 121, 54, 13, 18, 48, 202, 170, 3], [2, 85, 82, 246, 21, 7, 632, 9, 3], [2, 121, 54, 13, 18, 48, 202, 170, 3], [2, 633, 9, 3], [2, 121, 54, 13, 18, 48, 202, 170, 3], [2, 26, 65, 3], [2, 13, 7, 175, 11, 141, 176, 19, 7, 9, 6, 5, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 147, 4, 148, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 7, 59, 3], [2, 89, 96, 110, 7, 59, 4, 7, 25, 24, 8, 3], [2, 7, 10, 34, 14, 17, 8, 15, 8, 3], [2, 23, 4, 7, 243, 149, 19, 183, 184, 108, 13, 55, 122, 6, 5, 3], [2, 135, 4, 114, 236, 6, 5, 3], [2, 30, 40, 55, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 343, 4, 73, 249, 122, 4, 7, 174, 4, 250, 9, 3], [2, 12, 634, 3], [2, 635, 636, 13, 637, 638, 140, 9, 3], [2, 120, 639, 3], [2, 28, 4, 125, 103, 11, 344, 640, 9, 3], [2, 120, 641, 3], [2, 642, 4, 345, 20, 643, 346, 103, 9, 3], [2, 12, 169, 3], [2, 251, 4, 7, 243, 149, 19, 183, 184, 9, 3], [2, 644, 4, 7, 181, 4, 178, 3], [2, 118, 84, 21, 7, 645, 4, 646, 9, 3], [2, 12, 647, 3], [2, 648, 649, 9, 3], [2, 12, 650, 3], [2, 241, 90, 244, 651, 652, 7, 653, 4, 18, 654, 655, 21, 347, 9, 3], [2, 656, 11, 119, 98, 9, 3], [2, 12, 657, 3], [2, 189, 119, 98, 11, 348, 9, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 93, 13, 7, 124, 4, 109, 88, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 658, 18, 659, 660, 661, 11, 18, 252, 662, 663, 21, 190, 30, 319, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 101, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 135, 4, 114, 236, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 177, 4, 159, 203, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 51, 224, 97, 11, 185, 46, 9, 3], [2, 12, 349, 3], [2, 114, 350, 13, 7, 238, 212, 9, 3], [2, 12, 664, 665, 666, 3], [2, 197, 667, 668, 669, 172, 9, 3], [2, 120, 670, 671, 3], [2, 241, 672, 673, 21, 7, 126, 4, 351, 98, 9, 3], [2, 97, 84, 46, 160, 7, 51, 11, 674, 11, 347, 9, 3], [2, 12, 675, 3], [2, 253, 20, 254, 9, 3], [2, 173, 3], [2, 676, 7, 677, 4, 678, 41, 9, 3], [2, 12, 679, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 251, 4, 7, 253, 20, 254, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 73, 114, 156, 21, 7, 126, 4, 7, 299, 25, 129, 11, 255, 680, 9, 3], [2, 12, 681, 3], [2, 51, 682, 226, 84, 50, 227, 683, 11, 80, 46, 9, 3], [2, 12, 352, 3], [2, 251, 4, 7, 253, 20, 254, 9, 3], [2, 12, 684, 685, 3], [2, 7, 118, 56, 156, 13, 204, 9, 3], [2, 12, 686, 687, 3], [2, 688, 333, 9, 3], [2, 12, 689, 690, 3], [2, 77, 81, 7, 9, 8, 3], [2, 26, 65, 3], [2, 7, 22, 157, 158, 7, 9, 8, 3], [2, 13, 7, 175, 11, 141, 176, 19, 7, 9, 6, 5, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 11, 43, 14, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 27, 32, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 60, 187, 4, 105, 691, 9, 3], [2, 692, 12, 3], [2, 246, 21, 323, 9, 3], [2, 54, 13, 18, 48, 3], [2, 353, 204, 21, 693, 298, 4, 694, 695, 11, 696, 697, 9, 3], [2, 54, 13, 18, 48, 3], [2, 348, 131, 9, 3], [2, 698, 12, 3], [2, 699, 700, 354, 9, 3], [2, 701, 702, 12, 3], [2, 703, 9, 3], [2, 54, 13, 18, 48, 3], [2, 26, 65, 130, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 31, 6, 5, 3], [2, 147, 4, 148, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 93, 13, 7, 124, 4, 109, 88, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 7, 59, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 110, 8, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 93, 13, 7, 124, 4, 109, 88, 6, 5, 3], [2, 63, 83, 19, 24, 56, 71, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 18, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 12, 106, 107, 3], [2, 185, 11, 704, 705, 215, 21, 7, 355, 240, 4, 7, 706, 707, 97, 187, 9, 3], [2, 12, 356, 357, 3], [2, 708, 4, 7, 709, 231, 710, 21, 711, 11, 712, 9, 3], [2, 12, 713, 714, 3], [2, 127, 154, 111, 112, 9, 3], [2, 12, 205, 3], [2, 127, 154, 111, 112, 9, 3], [2, 12, 205, 3], [2, 715, 4, 716, 11, 717, 11, 4, 57, 141, 358, 20, 256, 9, 3], [2, 12, 718, 3], [2, 719, 11, 134, 720, 359, 19, 256, 9, 3], [2, 12, 721, 722, 3], [2, 723, 155, 179, 724, 9, 3], [2, 12, 725, 3], [2, 726, 15, 727, 128, 113, 80, 21, 197, 728, 11, 128, 113, 354, 9, 3], [2, 12, 729, 3], [2, 90, 4, 289, 328, 9, 3], [2, 12, 360, 3], [2, 730, 731, 732, 9, 3], [2, 12, 733, 3], [2, 119, 131, 302, 11, 119, 361, 734, 13, 735, 11, 736, 321, 9, 3], [2, 54, 13, 18, 48, 3], [2, 362, 737, 85, 82, 45, 9, 3], [2, 54, 13, 18, 48, 3], [2, 127, 738, 4, 7, 25, 24, 13, 9, 3], [2, 12, 739, 740, 3], [2, 77, 81, 7, 9, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 147, 4, 148, 6, 5, 3], [2, 23, 4, 44, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 101, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 108, 13, 55, 122, 6, 5, 3], [2, 90, 4, 741, 21, 7, 742, 4, 7, 743, 4, 344, 744, 61, 62, 9, 3], [2, 86, 12, 3], [2, 745, 746, 336, 11, 196, 61, 62, 9, 3], [2, 86, 12, 3], [2, 747, 50, 748, 749, 11, 750, 13, 206, 91, 363, 207, 125, 103, 61, 62, 9, 3], [2, 86, 12, 3], [2, 751, 13, 7, 90, 4, 752, 61, 62, 9, 3], [2, 86, 12, 3], [2, 753, 257, 4, 142, 105, 91, 143, 144, 61, 62, 9, 3], [2, 86, 12, 3], [2, 364, 754, 4, 11, 755, 756, 13, 142, 105, 91, 143, 144, 61, 62, 9, 3], [2, 86, 12, 3], [2, 757, 11, 758, 4, 142, 105, 91, 143, 144, 61, 62, 9, 3], [2, 86, 12, 3], [2, 126, 4, 287, 11, 759, 760, 13, 142, 105, 91, 143, 144, 61, 62, 9, 3], [2, 86, 12, 3], [2, 761, 4, 219, 762, 365, 20, 204, 763, 61, 62, 9, 3], [2, 90, 4, 342, 151, 764, 61, 62, 9, 3], [2, 87, 12, 3], [2, 73, 228, 20, 7, 304, 61, 62, 9, 3], [2, 86, 12, 3], [2, 90, 4, 765, 61, 62, 9, 3], [2, 86, 12, 3], [2, 766, 767, 314, 768, 315, 61, 62, 9, 3], [2, 87, 12, 3], [2, 73, 204, 769, 61, 62, 9, 3], [2, 87, 12, 3], [2, 770, 11, 313, 4, 771, 61, 62, 9, 3], [2, 366, 4, 25, 105, 228, 231, 309, 61, 62, 9, 3], [2, 87, 12, 3], [2, 87, 12, 3], [2, 97, 84, 46, 160, 7, 51, 11, 199, 192, 772, 11, 773, 774, 9, 3], [2, 356, 357, 12, 3], [2, 97, 84, 46, 160, 7, 51, 11, 775, 9, 3], [2, 349, 12, 3], [2, 93, 13, 124, 4, 7, 88, 4, 776, 777, 9, 3], [2, 232, 12, 3], [2, 778, 50, 779, 50, 780, 11, 781, 4, 782, 783, 9, 3], [2, 784, 12, 3], [2, 785, 11, 786, 787, 9, 3], [2, 788, 12, 3], [2, 789, 9, 3], [2, 790, 791, 12, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 7, 5, 4, 792, 56, 10, 294, 295, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 7, 793, 4, 285, 11, 7, 794, 795, 4, 796, 367, 9, 3], [2, 797, 12, 3], [2, 798, 4, 799, 800, 82, 9, 3], [2, 801, 802, 12, 3], [2, 368, 41, 803, 4, 7, 258, 369, 19, 370, 9, 3], [2, 371, 12, 3], [2, 368, 41, 804, 4, 7, 258, 369, 19, 370, 9, 3], [2, 371, 12, 3], [2, 247, 9, 3], [2, 54, 13, 18, 48, 247, 3], [2, 7, 805, 11, 245, 4, 248, 806, 249, 9, 3], [2, 807, 12, 3], [2, 808, 7, 809, 13, 810, 24, 21, 811, 365, 20, 812, 4, 7, 259, 372, 9, 3], [2, 54, 13, 18, 48, 259, 372, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 813, 4, 155, 814, 244, 373, 815, 9, 3], [2, 12, 374, 375, 242, 376, 198, 18, 377, 3], [2, 119, 131, 11, 816, 361, 172, 13, 817, 9, 3], [2, 54, 13, 18, 48, 3], [2, 339, 173, 19, 197, 331, 11, 332, 9, 3], [2, 12, 360, 3], [2, 173, 378, 21, 7, 60, 25, 818, 179, 9, 3], [2, 12, 819, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 177, 4, 159, 203, 6, 5, 3], [2, 77, 81, 7, 9, 8, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 164, 19, 165, 4, 166, 4, 85, 82, 50, 167, 11, 7, 39, 4, 92, 188, 3], [2, 85, 82, 21, 820, 9, 3], [2, 121, 54, 13, 18, 48, 3], [2, 260, 9, 3], [2, 121, 54, 13, 18, 48, 3], [2, 26, 65, 3], [2, 7, 22, 157, 158, 7, 9, 8, 3], [2, 13, 7, 175, 11, 141, 176, 19, 7, 9, 50, 6, 5, 8, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 7, 59, 3], [2, 89, 96, 110, 7, 59, 4, 7, 25, 24, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 78, 79, 11, 30, 40, 55, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 30, 40, 39, 6, 5, 3], [2, 101, 6, 5, 3], [2, 177, 4, 159, 203, 13, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 210, 4, 18, 267, 213, 4, 24, 9, 3], [2, 51, 821, 259, 822, 46, 9, 3], [2, 120, 145, 106, 107, 3], [2, 51, 297, 84, 11, 80, 46, 9, 3], [2, 12, 145, 106, 107, 3], [2, 51, 823, 84, 11, 80, 46, 9, 3], [2, 12, 145, 106, 107, 3], [2, 51, 824, 84, 11, 80, 46, 9, 3], [2, 12, 145, 106, 107, 3], [2, 12, 145, 106, 107, 3], [2, 51, 825, 84, 11, 80, 46, 9, 3], [2, 12, 145, 106, 107, 3], [2, 208, 4, 136, 11, 137, 20, 7, 133, 19, 7, 201, 4, 155, 379, 13, 380, 826, 9, 3], [2, 12, 827, 828, 829, 3], [2, 12, 830, 831, 56, 3], [2, 18, 235, 381, 290, 4, 140, 41, 382, 832, 9, 3], [2, 12, 833, 834, 3], [2, 12, 835, 836, 837, 3], [2, 186, 838, 21, 7, 839, 9, 3], [2, 12, 840, 841, 842, 843, 3], [2, 208, 4, 136, 11, 137, 20, 7, 383, 133, 9, 3], [2, 12, 261, 262, 3], [2, 208, 4, 136, 11, 137, 20, 7, 133, 19, 844, 845, 21, 373, 846, 9, 3], [2, 12, 261, 262, 3], [2, 208, 4, 136, 11, 137, 20, 7, 133, 19, 847, 848, 9, 3], [2, 12, 261, 262, 3], [2, 849, 235, 39, 18, 4, 24, 56, 174, 4, 250, 9, 3], [2, 12, 384, 385, 3], [2, 386, 11, 850, 4, 7, 174, 4, 250, 272, 4, 39, 9, 3], [2, 12, 384, 385, 3], [2, 88, 11, 851, 4, 852, 853, 9, 3], [2, 12, 854, 855, 856, 3], [2, 12, 857, 858, 327, 3], [2, 127, 154, 111, 112, 9, 3], [2, 12, 859, 205, 3], [2, 334, 860, 9, 3], [2, 12, 861, 862, 3], [2, 863, 864, 865, 387, 41, 249, 9, 3], [2, 12, 866, 867, 3], [2, 92, 215, 20, 279, 280, 150, 281, 282, 9, 3], [2, 12, 868, 86, 3], [2, 73, 63, 172, 21, 7, 126, 4, 134, 9, 3], [2, 120, 13, 388, 263, 869, 870, 3], [2, 871, 872, 873, 367, 9, 3], [2, 120, 13, 388, 263, 874, 389, 390, 3], [2, 195, 875, 9, 3], [2, 12, 18, 199, 876, 3], [2, 195, 877, 9, 3], [2, 878, 11, 195, 879, 152, 880, 881, 13, 201, 21, 11, 19, 256, 9, 3], [2, 12, 882, 883, 884, 885, 3], [2, 25, 886, 291, 9, 3], [2, 12, 887, 888, 889, 3], [2, 26, 65, 3], [2, 7, 22, 157, 158, 7, 9, 8, 3], [2, 13, 7, 175, 11, 141, 176, 19, 7, 9, 50, 6, 5, 8, 3], [2, 890, 4, 7, 891, 181, 892, 4, 7, 25, 24, 108, 13, 55, 122, 6, 5, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 182, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 296, 46, 152, 7, 362, 233, 220, 13, 71, 221, 6, 5, 3], [2, 177, 4, 159, 203, 13, 9, 3], [2, 893, 11, 894, 4, 248, 895, 896, 9, 3], [2, 12, 897, 3], [2, 73, 63, 21, 7, 126, 4, 351, 98, 9, 3], [2, 12, 898, 3], [2, 899, 4, 212, 103, 9, 3], [2, 12, 264, 3], [2, 292, 391, 11, 392, 257, 9, 3], [2, 12, 264, 3], [2, 900, 358, 21, 391, 11, 392, 257, 9, 3], [2, 12, 264, 3], [2, 901, 902, 13, 255, 903, 140, 9, 3], [2, 12, 904, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 34, 14, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 111, 177, 6, 5, 3], [2, 73, 381, 172, 9, 3], [2, 905, 12, 3], [2, 393, 214, 906, 9, 3], [2, 907, 12, 3], [2, 63, 20, 908, 909, 335, 9, 3], [2, 54, 13, 18, 48, 3], [2, 910, 9, 3], [2, 911, 12, 3], [2, 25, 320, 912, 9, 3], [2, 913, 12, 3], [2, 914, 9, 3], [2, 121, 54, 13, 18, 48, 3], [2, 915, 46, 11, 916, 20, 917, 9, 3], [2, 54, 13, 18, 48, 3], [2, 918, 366, 104, 7, 153, 80, 350, 9, 3], [2, 54, 13, 18, 48, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 164, 19, 165, 4, 166, 4, 85, 82, 50, 167, 11, 7, 39, 4, 92, 188, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 28, 41, 7, 45, 4, 24, 56, 64, 52, 14, 393, 263, 39, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 40, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 123, 4, 7, 59, 3], [2, 89, 96, 7, 10, 110, 8, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 101, 6, 5, 3], [2, 78, 79, 11, 30, 146, 55, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 919, 4, 920, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 3], [2, 12, 921, 394, 3], [2, 383, 922, 923, 9, 3], [2, 12, 924, 925, 374, 375, 242, 376, 198, 18, 377, 3], [2, 395, 229, 21, 7, 25, 168, 9, 3], [2, 12, 926, 927, 928, 3], [2, 395, 92, 378, 929, 11, 930, 9, 3], [2, 12, 931, 932, 3], [2, 343, 4, 7, 355, 238, 9, 3], [2, 12, 325, 232, 3], [2, 201, 933, 92, 9, 3], [2, 12, 934, 935, 936, 3], [2, 26, 65, 3], [2, 7, 22, 157, 158, 7, 9, 8, 3], [2, 13, 7, 175, 11, 141, 176, 19, 7, 9, 6, 5, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 11, 43, 14, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 8, 18, 8, 15, 8, 3], [2, 23, 4, 24, 6, 5, 3], [2, 937, 186, 938, 11, 186, 939, 9, 3], [2, 12, 940, 3], [2, 127, 154, 111, 112, 9, 3], [2, 12, 205, 3], [2, 396, 129, 4, 397, 346, 9, 3], [2, 12, 941, 3], [2, 942, 943, 265, 13, 85, 944, 9, 3], [2, 12, 398, 3], [2, 60, 187, 4, 7, 265, 11, 265, 140, 225, 9, 3], [2, 12, 398, 3], [2, 945, 387, 41, 7, 118, 19, 946, 77, 286, 947, 948, 19, 949, 950, 9, 3], [2, 48, 3], [2, 951, 129, 952, 21, 190, 11, 200, 953, 9, 3], [2, 12, 954, 955, 3], [2, 956, 382, 12, 399, 18, 258, 25, 317, 225, 9, 3], [2, 48, 3], [2, 957, 958, 959, 960, 9, 3], [2, 12, 961, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 962, 21, 218, 963, 30, 135, 6, 5, 3], [2, 353, 134, 964, 9, 3], [2, 965, 12, 3], [2, 133, 19, 7, 400, 151, 966, 9, 3], [2, 48, 3], [2, 85, 82, 967, 11, 968, 19, 85, 82, 152, 252, 223, 9, 3], [2, 389, 390, 969, 12, 3], [2, 288, 21, 118, 97, 970, 364, 200, 971, 9, 3], [2, 972, 973, 974, 12, 3], [2, 975, 4, 7, 976, 977, 9, 3], [2, 978, 12, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 164, 19, 165, 4, 166, 4, 85, 82, 50, 167, 11, 7, 39, 4, 92, 188, 3], [2, 260, 9, 3], [2, 48, 19, 260, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 146, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 89, 96, 7, 59, 4, 7, 25, 24, 110, 8, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 23, 4, 24, 6, 5, 3], [2, 115, 4, 116, 52, 104, 117, 6, 5, 3], [2, 979, 39, 18, 6, 5, 3], [2, 78, 79, 11, 30, 146, 55, 6, 5, 3], [2, 30, 146, 39, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 101, 6, 5, 3], [2, 63, 83, 19, 24, 56, 64, 11, 71, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 7, 10, 16, 34, 14, 8, 17, 8, 15, 8, 3], [2, 49, 4, 7, 10, 3], [2, 7, 10, 16, 53, 14, 18, 8, 15, 8, 3], [2, 27, 32, 6, 5, 3], [2, 51, 980, 46, 19, 57, 191, 4, 163, 162, 9, 3], [2, 12, 169, 3], [2, 51, 981, 46, 19, 57, 191, 4, 163, 162, 9, 3], [2, 12, 169, 3], [2, 51, 982, 46, 19, 57, 191, 4, 163, 162, 9, 3], [2, 12, 169, 3], [2, 51, 983, 46, 19, 218, 11, 984, 80, 9, 3], [2, 12, 985, 3], [2, 324, 4, 136, 11, 137, 21, 7, 986, 987, 988, 46, 19, 80, 11, 380, 168, 9, 3], [2, 12, 352, 3], [2, 989, 156, 990, 41, 991, 13, 992, 11, 993, 994, 9, 3], [2, 995, 996, 19, 997, 9, 3], [2, 12, 394, 3], [2, 266, 139, 998, 999, 1000, 19, 206, 207, 125, 103, 9, 3], [2, 12, 87, 3], [2, 266, 139, 1001, 13, 206, 207, 125, 103, 9, 3], [2, 12, 87, 3], [2, 401, 1002, 1003, 4, 206, 91, 363, 207, 125, 103, 9, 3], [2, 12, 87, 3], [2, 386, 4, 340, 174, 20, 129, 41, 402, 50, 266, 11, 396, 1004, 9, 3], [2, 12, 87, 3], [2, 401, 1005, 345, 13, 142, 105, 91, 143, 144, 9, 3], [2, 12, 87, 3], [2, 1006, 1007, 90, 1008, 4, 142, 105, 91, 143, 144, 9, 3], [2, 12, 87, 3], [2, 1009, 19, 403, 11, 1010, 1011, 9, 3], [2, 12, 1012, 3], [2, 153, 4, 7, 73, 56, 1013, 9, 3], [2, 12, 1014, 3], [2, 273, 4, 274, 275, 276, 277, 11, 278, 19, 7, 214, 179, 21, 7, 73, 9, 3], [2, 12, 1015, 3], [2, 402, 1016, 11, 150, 9, 3], [2, 12, 1017, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 18, 8, 15, 8, 11, 43, 14, 8, 17, 8, 15, 8, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 16, 34, 14, 182, 3], [2, 25, 1018, 4, 379, 9, 3], [2, 404, 405, 13, 406, 9, 3], [2, 180, 13, 18, 45, 229, 404, 405, 13, 406, 318, 3], [2, 397, 1019, 359, 21, 1020, 9, 3], [2, 48, 3], [2, 399, 18, 60, 25, 1021, 98, 19, 255, 9, 3], [2, 12, 106, 107, 3], [2, 98, 1022, 21, 7, 400, 151, 300, 1023, 4, 252, 301, 1024, 9, 3], [2, 12, 1025, 199, 341, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 7, 10, 16, 35, 14, 8, 17, 8, 15, 8, 11, 43, 14, 17, 8, 15, 8, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 31, 13, 22, 10, 6, 5, 3], [2, 33, 4, 10, 3], [2, 7, 10, 34, 14, 8, 3], [2, 49, 4, 7, 10, 3], [2, 1026, 1027, 192, 1028, 192, 1029, 8, 3], [2, 8, 3], [2, 27, 32, 6, 5, 3], [2, 1030, 13, 18, 1031, 131, 20, 196, 1032, 30, 135, 6, 5, 3], [2, 93, 13, 216, 4, 109, 88, 6, 5, 3], [2, 31, 6, 5, 3], [2, 8, 89, 1033, 1034, 9, 3], [2, 209, 1035, 3], [2, 1036, 11, 1037, 21, 25, 403, 11, 237, 1038, 9, 3], [2, 209, 1039, 3], [2, 245, 4, 7, 45, 173, 66, 7, 1040, 151, 7, 1041, 1042, 9, 3], [2, 1043, 1044, 3], [2, 150, 4, 128, 113, 1045, 1046, 9, 3], [2, 209, 1047, 3], [2, 1048, 1049, 160, 1050, 1051, 4, 1052, 91, 1053, 1054, 9, 3], [2, 209, 1055, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 75, 4, 42, 52, 76, 7, 10, 6, 5, 3], [2, 102, 4, 45, 60, 64, 6, 5, 3], [2, 36, 20, 37, 11, 26, 38, 6, 5, 3], [2, 74, 66, 57, 27, 6, 5, 3], [2, 30, 146, 13, 94, 21, 7, 95, 39, 6, 5, 3], [2, 72, 13, 22, 67, 6, 5, 3], [2, 28, 4, 5, 4, 29, 10, 6, 5, 3], [2, 23, 4, 24, 6, 5, 3], [2, 147, 4, 148, 6, 5, 3], [2, 23, 4, 44, 11, 47, 6, 5, 3], [2, 1056, 1057, 11, 230, 1058, 1059, 1060, 1061, 1062, 30, 135, 6, 5, 3], [2, 31, 6, 5, 3], [2, 27, 32, 6, 5, 3], [2, 30, 146, 55, 6, 5, 3], [2, 42, 4, 69, 70, 41, 7, 45, 6, 5, 3], [2, 99, 4, 100, 6, 5, 3]]\n",
            "Tensor of sequences from texts: [[2, 20, 21, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 149, 150, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 27, 33, 9, 71, 72, 48, 5, 4, 3], [2, 98, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 57, 73, 16, 21, 55, 28, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 208, 257, 106, 22, 21, 107, 11, 258, 209, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 208, 398, 22, 21, 107, 11, 258, 209, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 107, 11, 48, 99, 5, 4, 3], [2, 8, 14, 36, 12, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 8, 14, 36, 12, 7, 45, 7, 13, 7, 9, 43, 11, 259, 63, 12, 260, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 31, 399, 261, 400, 401, 210, 402, 403, 404, 405, 5, 4, 3], [2, 262, 40, 106, 5, 4, 3], [2, 20, 31, 6, 3], [2, 99, 406, 50, 78, 25, 6, 3], [2, 263, 176, 211, 264, 265, 9, 176, 16, 177, 151, 18, 67, 6, 3], [2, 89, 212, 17, 266, 267, 152, 268, 269, 6, 3], [2, 407, 9, 408, 270, 10, 16, 409, 271, 6, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 90, 11, 213, 108, 82, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 52, 22, 21, 109, 7, 3], [2, 8, 14, 35, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 90, 11, 123, 108, 82, 5, 4, 3], [2, 214, 17, 31, 153, 40, 178, 106, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 57, 73, 16, 21, 55, 28, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 29, 5, 4, 3], [2, 214, 17, 108, 31, 6, 5, 4, 3], [2, 6, 63, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 179, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 83, 215, 154, 410, 411, 6, 3], [2, 24, 124, 101, 155, 412, 17, 61, 125, 272, 211, 6, 3], [2, 50, 413, 25, 16, 216, 9, 414, 74, 6, 3], [2, 415, 273, 18, 156, 74, 84, 6, 3], [2, 126, 157, 110, 111, 6, 3], [2, 50, 416, 85, 78, 6, 3], [2, 417, 418, 18, 127, 112, 419, 420, 274, 421, 9, 422, 423, 6, 3], [2, 22, 424, 275, 425, 6, 3], [2, 70, 75, 6, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 426, 427, 16, 180, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 98, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 276, 428, 6, 3], [2, 277, 11, 429, 158, 18, 22, 67, 430, 6, 3], [2, 278, 431, 6, 3], [2, 279, 18, 432, 6, 3], [2, 70, 75, 6, 7, 3], [2, 6, 63, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 4, 26, 8, 14, 280, 7, 3], [2, 262, 40, 106, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 181, 182, 46, 11, 28, 48, 5, 4, 3], [2, 281, 47, 433, 46, 11, 28, 48, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 179, 3], [2, 44, 8, 3], [2, 434, 113, 128, 11, 282, 6, 3], [2, 183, 435, 436, 437, 283, 6, 3], [2, 438, 439, 6, 3], [2, 217, 440, 10, 111, 16, 284, 22, 285, 11, 129, 6, 3], [2, 441, 442, 6, 3], [2, 70, 75, 6, 7, 3], [2, 6, 63, 130, 3], [2, 19, 159, 14, 6, 63, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 29, 11, 19, 131, 52, 5, 4, 3], [2, 34, 8, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 443, 76, 6, 3], [2, 110, 128, 11, 444, 160, 6, 3], [2, 286, 184, 6, 3], [2, 160, 132, 287, 288, 47, 445, 9, 446, 6, 3], [2, 50, 218, 447, 25, 6, 3], [2, 58, 161, 185, 18, 448, 6, 3], [2, 219, 84, 449, 11, 6, 3], [2, 289, 270, 10, 6, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 290, 162, 450, 451, 9, 452, 453, 454, 6, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 52, 22, 21, 36, 7, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 98, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 20, 220, 291, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 292, 9, 293, 294, 163, 39, 107, 11, 48, 99, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 455, 52, 3], [2, 93, 94, 52, 22, 21, 109, 7, 3], [2, 44, 52, 3], [2, 93, 94, 52, 22, 21, 49, 7, 3], [2, 23, 32, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 295, 296, 40, 456, 47, 186, 133, 6, 3], [2, 457, 187, 50, 111, 16, 458, 459, 6, 3], [2, 460, 297, 461, 9, 298, 462, 6, 3], [2, 463, 221, 464, 6, 3], [2, 127, 112, 465, 466, 299, 6, 3], [2, 70, 75, 6, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 292, 9, 293, 294, 163, 39, 6, 3], [2, 300, 467, 301, 302, 468, 469, 86, 470, 6, 3], [2, 471, 472, 55, 473, 303, 304, 134, 6, 3], [2, 221, 135, 474, 188, 6, 3], [2, 50, 475, 164, 129, 25, 6, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 214, 17, 163, 39, 153, 40, 178, 106, 5, 4, 3], [2, 476, 305, 27, 33, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 209, 17, 163, 39, 6, 3], [2, 67, 57, 16, 477, 127, 112, 136, 478, 6, 3], [2, 479, 480, 6, 3], [2, 481, 117, 306, 307, 482, 25, 6, 3], [2, 118, 84, 483, 9, 308, 9, 219, 484, 6, 3], [2, 485, 309, 9, 156, 74, 6, 3], [2, 70, 75, 6, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 97, 16, 165, 137, 79, 76, 47, 166, 9, 30, 89, 97, 3], [2, 486, 6, 3], [2, 310, 6, 3], [2, 70, 75, 6, 7, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 57, 73, 16, 21, 55, 28, 5, 4, 3], [2, 29, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 45, 7, 13, 7, 3], [2, 44, 8, 3], [2, 20, 220, 291, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 67, 311, 18, 487, 298, 22, 488, 222, 6, 3], [2, 90, 11, 123, 82, 312, 223, 6, 3], [2, 489, 155, 152, 490, 189, 6, 3], [2, 491, 492, 9, 113, 186, 493, 6, 3], [2, 494, 12, 313, 495, 6, 3], [2, 190, 496, 9, 497, 117, 6, 3], [2, 190, 22, 167, 55, 498, 224, 6, 3], [2, 190, 499, 313, 18, 191, 6, 3], [2, 500, 225, 180, 189, 18, 501, 6, 3], [2, 70, 75, 6, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 20, 163, 39, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 57, 73, 16, 21, 55, 28, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 77, 113, 188, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 45, 7, 13, 7, 3], [2, 44, 8, 3], [2, 50, 288, 25, 16, 53, 192, 164, 135, 6, 3], [2, 10, 168, 3], [2, 502, 503, 11, 504, 261, 138, 9, 139, 505, 506, 507, 6, 3], [2, 10, 508, 509, 510, 3], [2, 213, 82, 511, 193, 87, 512, 6, 3], [2, 10, 314, 3], [2, 54, 133, 513, 47, 217, 514, 6, 3], [2, 10, 140, 3], [2, 54, 133, 515, 47, 217, 516, 6, 3], [2, 10, 140, 3], [2, 10, 140, 3], [2, 54, 133, 517, 47, 22, 518, 6, 3], [2, 10, 140, 3], [2, 54, 133, 519, 169, 47, 22, 315, 83, 520, 6, 3], [2, 10, 140, 3], [2, 54, 141, 194, 47, 194, 47, 141, 194, 9, 141, 194, 521, 6, 3], [2, 10, 522, 3], [2, 54, 22, 170, 11, 156, 523, 226, 6, 3], [2, 10, 65, 3], [2, 54, 22, 316, 11, 524, 525, 9, 227, 526, 6, 3], [2, 10, 65, 3], [2, 54, 22, 317, 170, 16, 318, 9, 319, 6, 3], [2, 10, 65, 3], [2, 54, 22, 317, 170, 11, 320, 9, 320, 527, 6, 3], [2, 10, 65, 3], [2, 54, 22, 228, 195, 6, 3], [2, 10, 65, 3], [2, 54, 22, 195, 11, 142, 9, 136, 12, 227, 6, 3], [2, 10, 65, 3], [2, 54, 321, 170, 11, 528, 22, 167, 6, 3], [2, 10, 65, 3], [2, 54, 22, 195, 11, 529, 530, 143, 6, 3], [2, 10, 65, 3], [2, 54, 531, 6, 3], [2, 10, 65, 3], [2, 54, 22, 226, 316, 6, 3], [2, 10, 65, 3], [2, 54, 22, 303, 142, 195, 6, 3], [2, 10, 65, 3], [2, 10, 65, 3], [2, 54, 22, 119, 142, 309, 6, 3], [2, 10, 65, 3], [2, 54, 22, 170, 11, 322, 323, 9, 171, 6, 3], [2, 10, 65, 3], [2, 54, 133, 532, 47, 31, 533, 6, 3], [2, 10, 140, 3], [2, 10, 65, 3], [2, 196, 534, 128, 535, 117, 9, 18, 536, 160, 6, 3], [2, 10, 537, 3], [2, 70, 75, 6, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 538, 539, 324, 540, 18, 191, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 197, 541, 542, 543, 10, 3], [2, 544, 180, 130, 17, 545, 9, 17, 90, 546, 3], [2, 229, 25, 16, 325, 22, 58, 326, 230, 6, 3], [2, 547, 10, 3], [2, 548, 6, 47, 549, 550, 551, 3], [2, 327, 25, 16, 229, 552, 231, 144, 18, 553, 554, 6, 3], [2, 555, 10, 3], [2, 6, 63, 130, 3], [2, 297, 9, 299, 328, 556, 6, 3], [2, 557, 120, 3], [2, 6, 63, 130, 3], [2, 558, 189, 171, 6, 3], [2, 559, 10, 3], [2, 560, 561, 9, 562, 161, 6, 3], [2, 232, 563, 564, 10, 3], [2, 233, 31, 16, 181, 182, 6, 3], [2, 153, 11, 56, 3], [2, 565, 57, 11, 137, 329, 30, 6, 3], [2, 198, 330, 566, 10, 3], [2, 229, 25, 16, 325, 22, 58, 326, 230, 6, 3], [2, 46, 11, 28, 3], [2, 567, 132, 16, 199, 172, 308, 224, 6, 3], [2, 568, 10, 3], [2, 6, 63, 130, 3], [2, 37, 17, 6, 234, 26, 8, 5, 4, 3], [2, 8, 14, 36, 12, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 8, 14, 36, 12, 7, 45, 7, 13, 7, 9, 43, 12, 7, 260, 3], [2, 569, 64, 83, 136, 9, 142, 331, 570, 9, 571, 572, 235, 10, 6, 3], [2, 573, 10, 3], [2, 574, 11, 53, 85, 143, 6, 3], [2, 575, 10, 3], [2, 58, 85, 84, 118, 576, 42, 6, 3], [2, 577, 10, 3], [2, 236, 578, 279, 18, 22, 167, 6, 3], [2, 579, 197, 10, 3], [2, 580, 158, 16, 581, 582, 583, 6, 3], [2, 584, 10, 3], [2, 585, 112, 296, 586, 6, 3], [2, 587, 10, 3], [2, 183, 9, 199, 588, 85, 224, 6, 3], [2, 589, 10, 3], [2, 237, 6, 3], [2, 46, 11, 28, 3], [2, 238, 590, 18, 591, 6, 3], [2, 592, 10, 3], [2, 70, 75, 259, 63, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 29, 5, 4, 3], [2, 97, 16, 165, 137, 79, 76, 47, 166, 9, 30, 89, 3], [2, 593, 594, 595, 18, 218, 6, 3], [2, 121, 46, 11, 28, 200, 169, 3], [2, 121, 46, 11, 28, 200, 169, 3], [2, 79, 76, 236, 18, 596, 6, 3], [2, 121, 46, 11, 28, 200, 169, 3], [2, 597, 6, 3], [2, 121, 46, 11, 28, 200, 169, 3], [2, 6, 63, 3], [2, 11, 173, 9, 145, 174, 16, 6, 5, 4, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 149, 150, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 109, 52, 22, 21, 7, 3], [2, 8, 35, 12, 15, 7, 13, 7, 3], [2, 20, 233, 31, 16, 181, 182, 107, 11, 48, 99, 5, 4, 3], [2, 77, 113, 188, 5, 4, 3], [2, 27, 33, 48, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 332, 67, 239, 99, 30, 201, 6, 3], [2, 10, 598, 3], [2, 599, 600, 11, 601, 602, 143, 6, 3], [2, 120, 603, 3], [2, 24, 124, 101, 9, 333, 604, 6, 3], [2, 120, 605, 3], [2, 606, 334, 17, 607, 335, 101, 6, 3], [2, 10, 168, 3], [2, 240, 233, 31, 16, 181, 182, 6, 3], [2, 153, 178, 106, 3], [2, 117, 78, 18, 608, 609, 6, 3], [2, 10, 610, 3], [2, 611, 612, 6, 3], [2, 10, 613, 3], [2, 231, 83, 234, 614, 615, 616, 617, 618, 18, 336, 6, 3], [2, 619, 9, 118, 84, 6, 3], [2, 10, 620, 3], [2, 190, 118, 84, 9, 337, 6, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 90, 11, 123, 108, 82, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 621, 622, 623, 624, 9, 241, 625, 626, 18, 191, 27, 33, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 98, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 77, 113, 188, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 175, 131, 52, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 50, 218, 85, 9, 183, 25, 6, 3], [2, 10, 338, 3], [2, 113, 339, 11, 228, 210, 6, 3], [2, 10, 627, 340, 87, 628, 3], [2, 196, 629, 630, 631, 144, 6, 3], [2, 120, 632, 87, 633, 3], [2, 231, 634, 635, 18, 125, 341, 84, 6, 3], [2, 85, 78, 25, 162, 50, 9, 636, 9, 336, 6, 3], [2, 10, 637, 3], [2, 39, 17, 242, 6, 3], [2, 56, 3], [2, 638, 639, 640, 40, 6, 3], [2, 10, 641, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 240, 39, 17, 242, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 67, 113, 128, 18, 125, 284, 22, 129, 9, 243, 285, 6, 3], [2, 10, 642, 3], [2, 50, 643, 219, 78, 47, 220, 644, 9, 74, 25, 6, 3], [2, 10, 342, 3], [2, 240, 39, 17, 242, 6, 3], [2, 10, 645, 646, 3], [2, 117, 55, 128, 11, 202, 6, 3], [2, 10, 647, 648, 3], [2, 649, 227, 6, 3], [2, 10, 650, 651, 3], [2, 70, 75, 6, 7, 3], [2, 6, 63, 3], [2, 19, 159, 14, 6, 7, 3], [2, 11, 173, 9, 145, 174, 16, 6, 5, 4, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 9, 43, 12, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 23, 32, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 58, 161, 103, 185, 6, 3], [2, 652, 10, 3], [2, 236, 18, 310, 6, 3], [2, 46, 11, 28, 3], [2, 343, 202, 18, 653, 283, 654, 655, 9, 656, 657, 6, 3], [2, 46, 11, 28, 3], [2, 337, 132, 6, 3], [2, 658, 10, 3], [2, 344, 659, 345, 6, 3], [2, 660, 661, 10, 3], [2, 662, 6, 3], [2, 46, 11, 28, 3], [2, 6, 63, 130, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 29, 5, 4, 3], [2, 149, 150, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 90, 11, 123, 108, 82, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 52, 22, 21, 109, 7, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 90, 11, 123, 108, 82, 5, 4, 3], [2, 57, 73, 16, 21, 55, 28, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 45, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 10, 104, 105, 3], [2, 183, 9, 663, 346, 212, 18, 347, 230, 664, 665, 85, 161, 6, 3], [2, 10, 666, 348, 3], [2, 667, 668, 222, 328, 18, 669, 9, 670, 6, 3], [2, 10, 340, 87, 671, 3], [2, 126, 157, 110, 111, 6, 3], [2, 10, 203, 3], [2, 126, 157, 110, 111, 6, 3], [2, 10, 203, 3], [2, 672, 673, 9, 674, 9, 53, 145, 349, 17, 119, 6, 3], [2, 10, 675, 3], [2, 676, 9, 136, 677, 204, 16, 119, 6, 3], [2, 10, 678, 679, 3], [2, 680, 158, 151, 681, 6, 3], [2, 10, 682, 3], [2, 683, 13, 684, 127, 112, 74, 18, 196, 685, 9, 127, 112, 345, 6, 3], [2, 10, 686, 3], [2, 83, 274, 315, 6, 3], [2, 10, 350, 3], [2, 687, 688, 689, 6, 3], [2, 10, 690, 3], [2, 118, 132, 287, 9, 118, 351, 144, 11, 691, 9, 692, 307, 6, 3], [2, 46, 11, 28, 3], [2, 352, 693, 79, 76, 42, 6, 3], [2, 46, 11, 28, 3], [2, 126, 694, 22, 21, 11, 6, 3], [2, 10, 695, 3], [2, 70, 75, 6, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 149, 150, 5, 4, 3], [2, 20, 31, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 98, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 107, 11, 48, 99, 5, 4, 3], [2, 83, 696, 18, 697, 698, 333, 699, 59, 60, 6, 3], [2, 80, 10, 3], [2, 700, 701, 323, 9, 171, 59, 60, 6, 3], [2, 80, 10, 3], [2, 171, 47, 702, 703, 9, 704, 11, 205, 86, 353, 88, 124, 101, 59, 60, 6, 3], [2, 80, 10, 3], [2, 705, 11, 83, 706, 59, 60, 6, 3], [2, 80, 10, 3], [2, 707, 244, 88, 103, 86, 146, 147, 59, 60, 6, 3], [2, 80, 10, 3], [2, 354, 708, 9, 709, 710, 11, 88, 103, 86, 146, 147, 59, 60, 6, 3], [2, 80, 10, 3], [2, 131, 9, 711, 88, 103, 86, 146, 147, 59, 60, 6, 3], [2, 80, 10, 3], [2, 125, 272, 9, 712, 713, 11, 88, 103, 86, 146, 147, 59, 60, 6, 3], [2, 80, 10, 3], [2, 714, 180, 715, 245, 17, 202, 355, 59, 60, 6, 3], [2, 83, 331, 154, 716, 59, 60, 6, 3], [2, 81, 10, 3], [2, 67, 186, 17, 289, 59, 60, 6, 3], [2, 80, 10, 3], [2, 83, 717, 59, 60, 6, 3], [2, 80, 10, 3], [2, 718, 356, 301, 356, 302, 59, 60, 6, 3], [2, 81, 10, 3], [2, 67, 202, 355, 59, 60, 6, 3], [2, 81, 10, 3], [2, 719, 9, 300, 720, 59, 60, 6, 3], [2, 357, 22, 103, 186, 222, 295, 59, 60, 6, 3], [2, 81, 10, 3], [2, 81, 10, 3], [2, 85, 78, 25, 162, 50, 9, 198, 246, 721, 87, 9, 722, 6, 3], [2, 723, 348, 10, 3], [2, 85, 78, 25, 162, 50, 9, 724, 6, 3], [2, 338, 10, 3], [2, 90, 11, 123, 82, 725, 726, 6, 3], [2, 223, 10, 3], [2, 727, 47, 728, 47, 729, 9, 730, 731, 732, 6, 3], [2, 733, 10, 3], [2, 734, 9, 735, 736, 6, 3], [2, 737, 10, 3], [2, 738, 6, 3], [2, 739, 87, 740, 10, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 4, 741, 55, 8, 14, 280, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 742, 271, 9, 743, 744, 745, 358, 6, 3], [2, 746, 10, 3], [2, 747, 748, 749, 76, 6, 3], [2, 750, 751, 10, 3], [2, 359, 40, 752, 247, 360, 16, 361, 6, 3], [2, 362, 10, 3], [2, 359, 40, 753, 247, 360, 16, 361, 6, 3], [2, 362, 10, 3], [2, 237, 6, 3], [2, 46, 11, 28, 237, 3], [2, 754, 9, 235, 238, 755, 239, 6, 3], [2, 756, 10, 3], [2, 757, 758, 11, 759, 21, 18, 201, 245, 17, 760, 248, 363, 6, 3], [2, 46, 11, 28, 248, 363, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 761, 158, 762, 234, 364, 763, 6, 3], [2, 10, 365, 232, 366, 197, 367, 3], [2, 118, 132, 9, 764, 351, 144, 11, 765, 6, 3], [2, 46, 11, 28, 3], [2, 327, 56, 16, 196, 318, 9, 319, 6, 3], [2, 10, 350, 3], [2, 56, 204, 18, 58, 22, 766, 151, 6, 3], [2, 10, 767, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 175, 131, 52, 5, 4, 3], [2, 70, 75, 6, 7, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 97, 16, 165, 137, 79, 76, 47, 166, 9, 30, 89, 97, 3], [2, 79, 76, 18, 768, 6, 3], [2, 121, 46, 11, 28, 3], [2, 249, 6, 3], [2, 121, 46, 11, 28, 3], [2, 6, 63, 3], [2, 19, 159, 14, 6, 7, 3], [2, 11, 173, 9, 145, 174, 16, 6, 47, 5, 4, 7, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 109, 52, 22, 21, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 71, 72, 9, 27, 33, 48, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 27, 33, 30, 5, 4, 3], [2, 98, 5, 4, 3], [2, 175, 131, 52, 11, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 208, 257, 106, 21, 6, 3], [2, 50, 769, 248, 770, 25, 6, 3], [2, 120, 148, 104, 105, 3], [2, 50, 282, 78, 9, 74, 25, 6, 3], [2, 10, 148, 104, 105, 3], [2, 50, 771, 78, 9, 74, 25, 6, 3], [2, 10, 148, 104, 105, 3], [2, 50, 772, 78, 9, 74, 25, 6, 3], [2, 10, 148, 104, 105, 3], [2, 10, 148, 104, 105, 3], [2, 50, 773, 78, 9, 74, 25, 6, 3], [2, 10, 148, 104, 105, 3], [2, 206, 138, 9, 139, 17, 134, 16, 172, 158, 368, 11, 369, 774, 6, 3], [2, 10, 775, 776, 777, 3], [2, 10, 778, 779, 87, 780, 3], [2, 225, 370, 276, 143, 40, 250, 781, 6, 3], [2, 10, 782, 783, 3], [2, 10, 784, 785, 786, 3], [2, 184, 250, 18, 787, 6, 3], [2, 10, 788, 789, 87, 790, 791, 3], [2, 206, 138, 9, 139, 17, 371, 134, 6, 3], [2, 10, 251, 252, 3], [2, 206, 138, 9, 139, 17, 134, 16, 792, 793, 18, 364, 324, 6, 3], [2, 10, 251, 252, 3], [2, 206, 138, 9, 139, 17, 134, 16, 794, 795, 6, 3], [2, 10, 251, 252, 3], [2, 372, 225, 30, 141, 193, 21, 55, 30, 201, 6, 3], [2, 10, 373, 374, 3], [2, 375, 9, 796, 30, 201, 99, 30, 6, 3], [2, 10, 373, 374, 3], [2, 82, 9, 797, 798, 799, 6, 3], [2, 10, 800, 801, 802, 3], [2, 10, 803, 804, 314, 3], [2, 126, 157, 110, 111, 6, 3], [2, 10, 805, 203, 3], [2, 321, 806, 6, 3], [2, 10, 807, 808, 3], [2, 809, 810, 811, 376, 40, 239, 6, 3], [2, 10, 812, 813, 3], [2, 89, 212, 17, 266, 267, 152, 268, 269, 6, 3], [2, 10, 814, 80, 3], [2, 67, 57, 144, 18, 125, 136, 6, 3], [2, 120, 11, 377, 253, 815, 816, 3], [2, 346, 817, 818, 358, 6, 3], [2, 120, 11, 377, 253, 819, 378, 3], [2, 119, 820, 6, 3], [2, 10, 193, 821, 198, 822, 3], [2, 119, 823, 6, 3], [2, 379, 9, 119, 824, 155, 379, 825, 11, 172, 18, 9, 16, 119, 6, 3], [2, 10, 826, 827, 828, 3], [2, 141, 22, 829, 277, 6, 3], [2, 10, 830, 831, 832, 3], [2, 6, 63, 3], [2, 19, 159, 14, 6, 7, 3], [2, 11, 173, 9, 145, 174, 16, 6, 47, 5, 4, 7, 3], [2, 833, 834, 178, 835, 22, 21, 107, 11, 48, 99, 5, 4, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 179, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 281, 25, 155, 352, 189, 46, 11, 28, 48, 5, 4, 3], [2, 175, 131, 52, 11, 6, 3], [2, 836, 9, 837, 238, 838, 275, 6, 3], [2, 10, 839, 3], [2, 67, 57, 18, 125, 341, 84, 6, 3], [2, 10, 840, 3], [2, 841, 210, 101, 6, 3], [2, 10, 254, 3], [2, 278, 380, 9, 381, 244, 6, 3], [2, 10, 254, 3], [2, 842, 349, 18, 380, 9, 381, 244, 6, 3], [2, 10, 254, 3], [2, 843, 844, 11, 243, 172, 143, 6, 3], [2, 10, 845, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 35, 12, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 110, 175, 5, 4, 3], [2, 67, 370, 144, 6, 3], [2, 846, 10, 3], [2, 382, 177, 847, 6, 3], [2, 848, 10, 3], [2, 57, 17, 344, 849, 322, 6, 3], [2, 46, 11, 28, 3], [2, 850, 6, 3], [2, 851, 10, 3], [2, 22, 306, 852, 6, 3], [2, 853, 10, 3], [2, 854, 6, 3], [2, 121, 46, 11, 28, 3], [2, 855, 25, 9, 856, 17, 857, 6, 3], [2, 46, 11, 28, 3], [2, 858, 357, 102, 156, 74, 339, 6, 3], [2, 46, 11, 28, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 97, 16, 165, 137, 79, 76, 47, 166, 9, 30, 89, 97, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 24, 40, 42, 21, 55, 62, 51, 12, 382, 253, 30, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 33, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 122, 52, 3], [2, 93, 94, 8, 109, 7, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 98, 5, 4, 3], [2, 71, 72, 9, 27, 77, 48, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 859, 860, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 3], [2, 10, 861, 383, 3], [2, 371, 862, 863, 6, 3], [2, 10, 864, 365, 232, 366, 197, 367, 3], [2, 384, 187, 18, 22, 167, 6, 3], [2, 10, 865, 866, 87, 867, 3], [2, 384, 89, 204, 868, 9, 869, 6, 3], [2, 10, 870, 871, 3], [2, 332, 347, 228, 6, 3], [2, 10, 312, 223, 3], [2, 172, 872, 89, 6, 3], [2, 10, 873, 874, 875, 3], [2, 6, 63, 3], [2, 19, 159, 14, 6, 7, 3], [2, 11, 173, 9, 145, 174, 16, 6, 5, 4, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 8, 14, 36, 12, 7, 9, 43, 12, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 7, 45, 7, 13, 7, 3], [2, 20, 21, 5, 4, 3], [2, 876, 184, 877, 9, 184, 878, 6, 3], [2, 10, 879, 3], [2, 126, 157, 110, 111, 6, 3], [2, 10, 203, 3], [2, 385, 129, 386, 335, 6, 3], [2, 10, 880, 3], [2, 881, 882, 255, 11, 79, 883, 6, 3], [2, 10, 387, 3], [2, 58, 161, 255, 9, 255, 143, 185, 6, 3], [2, 10, 387, 3], [2, 884, 376, 40, 117, 16, 885, 70, 215, 886, 73, 16, 887, 888, 6, 3], [2, 28, 3], [2, 889, 129, 890, 18, 191, 9, 199, 891, 6, 3], [2, 10, 892, 893, 3], [2, 894, 250, 10, 388, 247, 22, 304, 185, 6, 3], [2, 28, 3], [2, 895, 896, 245, 897, 6, 3], [2, 10, 898, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 899, 18, 216, 900, 27, 77, 5, 4, 3], [2, 343, 136, 187, 6, 3], [2, 901, 10, 3], [2, 134, 16, 389, 154, 902, 6, 3], [2, 28, 3], [2, 79, 76, 290, 9, 903, 16, 79, 76, 155, 241, 160, 6, 3], [2, 378, 904, 10, 3], [2, 273, 18, 117, 85, 905, 354, 199, 906, 6, 3], [2, 907, 908, 87, 909, 10, 3], [2, 910, 911, 912, 6, 3], [2, 913, 10, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 97, 16, 165, 137, 79, 76, 47, 166, 9, 30, 89, 97, 3], [2, 249, 6, 3], [2, 28, 16, 249, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 77, 11, 91, 18, 92, 30, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 93, 94, 52, 22, 21, 109, 7, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 20, 21, 5, 4, 3], [2, 114, 115, 51, 102, 116, 5, 4, 3], [2, 372, 30, 141, 193, 5, 4, 3], [2, 71, 72, 9, 27, 77, 48, 5, 4, 3], [2, 27, 77, 30, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 98, 5, 4, 3], [2, 57, 73, 16, 21, 55, 62, 9, 28, 5, 4, 3], [2, 95, 96, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 8, 14, 35, 12, 7, 15, 7, 13, 7, 3], [2, 44, 8, 3], [2, 8, 14, 49, 12, 45, 7, 13, 7, 3], [2, 23, 32, 5, 4, 3], [2, 50, 914, 25, 16, 53, 192, 164, 135, 6, 3], [2, 10, 168, 3], [2, 50, 915, 25, 16, 53, 192, 164, 135, 6, 3], [2, 10, 168, 3], [2, 50, 916, 25, 16, 53, 192, 164, 135, 6, 3], [2, 10, 168, 3], [2, 50, 917, 25, 16, 216, 9, 918, 74, 6, 3], [2, 10, 919, 3], [2, 311, 138, 9, 139, 18, 920, 921, 922, 25, 16, 74, 9, 369, 167, 6, 3], [2, 10, 342, 3], [2, 390, 128, 923, 40, 924, 11, 391, 9, 925, 391, 6, 3], [2, 926, 927, 16, 928, 6, 3], [2, 10, 383, 3], [2, 256, 142, 215, 929, 930, 16, 205, 88, 124, 101, 6, 3], [2, 10, 81, 3], [2, 256, 142, 931, 11, 205, 88, 124, 101, 6, 3], [2, 10, 81, 3], [2, 392, 932, 933, 205, 86, 353, 88, 124, 101, 6, 3], [2, 10, 81, 3], [2, 375, 329, 30, 17, 129, 40, 393, 47, 256, 9, 385, 934, 6, 3], [2, 10, 81, 3], [2, 392, 935, 334, 11, 88, 103, 86, 146, 147, 6, 3], [2, 10, 81, 3], [2, 936, 937, 83, 938, 88, 103, 86, 146, 147, 6, 3], [2, 10, 81, 3], [2, 939, 16, 394, 9, 940, 941, 6, 3], [2, 10, 942, 3], [2, 156, 67, 55, 177, 6, 3], [2, 10, 943, 3], [2, 263, 176, 211, 264, 265, 9, 176, 16, 177, 151, 18, 67, 6, 3], [2, 10, 944, 3], [2, 393, 945, 9, 152, 6, 3], [2, 10, 946, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 45, 7, 13, 7, 9, 43, 12, 7, 15, 7, 13, 7, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 14, 35, 12, 179, 3], [2, 22, 947, 368, 6, 3], [2, 395, 396, 11, 397, 6, 3], [2, 153, 11, 42, 187, 395, 396, 11, 397, 305, 3], [2, 386, 948, 204, 18, 949, 6, 3], [2, 28, 3], [2, 388, 58, 22, 950, 84, 16, 243, 6, 3], [2, 10, 104, 105, 3], [2, 84, 951, 18, 389, 154, 286, 952, 241, 160, 390, 6, 3], [2, 10, 953, 198, 330, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 8, 14, 36, 12, 7, 15, 7, 13, 7, 9, 43, 12, 15, 7, 13, 7, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 29, 11, 19, 8, 5, 4, 3], [2, 34, 8, 3], [2, 8, 35, 12, 7, 3], [2, 44, 8, 3], [2, 954, 955, 246, 956, 246, 957, 7, 3], [2, 7, 3], [2, 23, 32, 5, 4, 3], [2, 958, 11, 959, 132, 17, 171, 960, 27, 77, 5, 4, 3], [2, 90, 11, 213, 108, 82, 5, 4, 3], [2, 29, 5, 4, 3], [2, 961, 962, 963, 6, 3], [2, 207, 964, 3], [2, 965, 9, 966, 18, 22, 394, 9, 226, 151, 6, 3], [2, 207, 967, 3], [2, 235, 42, 56, 64, 968, 154, 969, 970, 6, 3], [2, 971, 972, 3], [2, 152, 127, 112, 135, 973, 6, 3], [2, 207, 974, 3], [2, 975, 976, 162, 977, 978, 979, 86, 980, 981, 6, 3], [2, 207, 982, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 68, 41, 51, 69, 8, 5, 4, 3], [2, 100, 42, 58, 62, 5, 4, 3], [2, 37, 17, 6, 9, 6, 38, 5, 4, 3], [2, 56, 64, 53, 23, 5, 4, 3], [2, 27, 77, 11, 91, 18, 92, 30, 5, 4, 3], [2, 66, 11, 19, 8, 5, 4, 3], [2, 24, 4, 26, 8, 5, 4, 3], [2, 20, 21, 5, 4, 3], [2, 149, 150, 5, 4, 3], [2, 20, 31, 9, 39, 5, 4, 3], [2, 983, 984, 9, 221, 985, 986, 987, 988, 989, 27, 77, 5, 4, 3], [2, 29, 5, 4, 3], [2, 23, 32, 5, 4, 3], [2, 27, 77, 48, 5, 4, 3], [2, 41, 25, 61, 40, 42, 5, 4, 3], [2, 95, 96, 5, 4, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LovuNqEV_P6C",
        "outputId": "282e68ec-72dd-44c8-d381-ff58f5545da9"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\r\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 20]), TensorShape([64, 19]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NtI_tDZ_0Fx",
        "outputId": "567c5ec8-ef2e-4398-fe4d-0412f6d2369d"
      },
      "source": [
        "# Important parameters\r\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\r\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\r\n",
        "max_length_input = example_input_batch.shape[1]\r\n",
        "max_length_output = example_target_batch.shape[1]\r\n",
        "print(\r\n",
        "    f\"vocab_inp_size (gloss): {vocab_inp_size}\\n\" + \r\n",
        "    f\"vocab_tar_size (en): {vocab_tar_size}\\n\" + \r\n",
        "    f\"max_length_input (gloss): {max_length_input}\\n\" + \r\n",
        "    f\"max_length_output (en): {max_length_output}\\n\"\r\n",
        ")\r\n",
        "\r\n",
        "embedding_dim = 256 #@param {is_template:true}\r\n",
        "units = 1024 #@param {is_template:true}\r\n",
        "steps_per_epoch = num_examples//BATCH_SIZE"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_inp_size (gloss): 1063\n",
            "vocab_tar_size (en): 990\n",
            "max_length_input (gloss): 20\n",
            "max_length_output (en): 19\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcN7IoQlBpG7"
      },
      "source": [
        "##### Encoder Class\r\n",
        "\r\n",
        "class Encoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "\r\n",
        "    ##________ LSTM layer in Encoder ------- ##\r\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def call(self, x, hidden):\r\n",
        "    x = self.embedding(x)\r\n",
        "    # output: whole_seq_output, final_memory_state, final_carry_stat\r\n",
        "    output, h, c = self.lstm_layer(x, initial_state = hidden)\r\n",
        "    return output, h, c\r\n",
        "\r\n",
        "  def initialize_hidden_state(self):\r\n",
        "    return [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEBIVbAZDX7d",
        "outputId": "cd896e0d-2084-4631-81e7-fe4b5e05af88"
      },
      "source": [
        "## Test Encoder Stack\r\n",
        "\r\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "# sample input\r\n",
        "sample_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\r\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\r\n",
        "print ('Encoder h vector shape: (batch size, units) {}'.format(sample_h.shape))\r\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
            "Encoder h vector shape: (batch size, units) (64, 1024)\n",
            "Encoder c vector shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ckgrjs-IsV_"
      },
      "source": [
        "##### Decoder Class.\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self, \r\n",
        "               vocab_size, \r\n",
        "               embedding_dim, \r\n",
        "               dec_units, \r\n",
        "               batch_sz, \r\n",
        "               attention_type='luong'):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.attention_type = attention_type\r\n",
        "\r\n",
        "    # Embedding Layer\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "\r\n",
        "    #Final Dense layer on which softmax will be applied\r\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    # Define the fundamental cell for decoder recurrent structure\r\n",
        "    self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\r\n",
        "\r\n",
        "    # Sampler\r\n",
        "    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\r\n",
        "\r\n",
        "    # Create attention mechanism with memory = None\r\n",
        "    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \r\n",
        "                                                              None, \r\n",
        "                                                              self.batch_sz*[max_length_input], \r\n",
        "                                                              self.attention_type)\r\n",
        "\r\n",
        "    # Wrap attention mechanism with the fundamental rnn cell of decoder\r\n",
        "    self.rnn_cell = self.build_rnn_cell(batch_sz)\r\n",
        "\r\n",
        "    # Define the decoder with respect to fundamental rnn cell\r\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\r\n",
        "\r\n",
        "\r\n",
        "  def build_rnn_cell(self, batch_sz):\r\n",
        "    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \r\n",
        "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\r\n",
        "    return rnn_cell\r\n",
        "\r\n",
        "  def build_attention_mechanism(self, \r\n",
        "                                dec_units, \r\n",
        "                                memory, \r\n",
        "                                memory_sequence_length, \r\n",
        "                                attention_type='luong'):\r\n",
        "    # ------------- #\r\n",
        "    # attention_type: Which sort of attention (Bahdanau, Luong)\r\n",
        "    # dec_units: final dimension of attention outputs \r\n",
        "    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\r\n",
        "    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\r\n",
        "\r\n",
        "    if(attention_type=='bahdanau'):\r\n",
        "      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\r\n",
        "    else:\r\n",
        "      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\r\n",
        "\r\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\r\n",
        "    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\r\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\r\n",
        "    return decoder_initial_state\r\n",
        "\r\n",
        "\r\n",
        "  def call(self, inputs, initial_state):\r\n",
        "    x = self.embedding(inputs)\r\n",
        "    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output-1])\r\n",
        "    return outputs"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57rmV_vrNvU4",
        "outputId": "695c6014-00ec-4baa-9a79-f39daafb102a"
      },
      "source": [
        "# Test decoder stack\r\n",
        "\r\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 'luong')\r\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\r\n",
        "decoder.attention_mechanism.setup_memory(sample_output)\r\n",
        "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\r\n",
        "\r\n",
        "\r\n",
        "sample_decoder_outputs = decoder(sample_x, initial_state)\r\n",
        "\r\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder Outputs Shape:  (64, 18, 990)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVgJHgHXOopb"
      },
      "source": [
        "# Optimizer and loss function\r\n",
        "learning_rate = 0.1 #@param\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\r\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\r\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\r\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\r\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\r\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \r\n",
        "  loss = mask * loss\r\n",
        "  loss = tf.reduce_mean(loss)\r\n",
        "  return loss"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9TXDHtDRMi3"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voKv0KX2RNaY"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\r\n",
        "\r\n",
        "    dec_input = targ[ : , :-1 ] # Ignore <end> token\r\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\r\n",
        "\r\n",
        "    # Set the AttentionMechanism object with encoder_outputs\r\n",
        "    decoder.attention_mechanism.setup_memory(enc_output)\r\n",
        "\r\n",
        "    # Create AttentionWrapperState as initial_state for decoder\r\n",
        "    decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\r\n",
        "    pred = decoder(dec_input, decoder_initial_state)\r\n",
        "    logits = pred.rnn_output\r\n",
        "    loss = loss_function(real, logits)\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "  # Note: Gradient Tape before applying: \r\n",
        "  # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#processing_gradients_before_applying_them_2\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return loss"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Dj7Na-VMIq",
        "outputId": "7decfbcb-e8af-4079-8db9-22fe6e658c1d"
      },
      "source": [
        "EPOCHS = 100 #@param\r\n",
        "\r\n",
        "costs = []\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "  print(enc_hidden[0].shape, enc_hidden[1].shape)\r\n",
        "\r\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  # saving (checkpoint) the model every 10 epochs\r\n",
        "  if (epoch + 1) % 10 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "    costs.append(total_loss / )\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\r\n",
        "\r\n",
        "  # plot the cost\r\n",
        "plt.plot(costs)\r\n",
        "plt.ylabel('cost')\r\n",
        "plt.xlabel('epochs (per 10)')\r\n",
        "plt.title(\"Learning rate = \" + str(learning_rate))\r\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1024) (64, 1024)\n",
            "Epoch 1 Batch 0 Loss 2.4965\n",
            "Epoch 1 Loss 1401.2976\n",
            "Time taken for 1 epoch 3.9551737308502197 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 2 Batch 0 Loss 7795.7085\n",
            "Epoch 2 Loss 4749.1943\n",
            "Time taken for 1 epoch 1.0135548114776611 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 3 Batch 0 Loss 6624.0161\n",
            "Epoch 3 Loss 4812.6030\n",
            "Time taken for 1 epoch 1.0317623615264893 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 4 Batch 0 Loss 5884.6958\n",
            "Epoch 4 Loss 4586.0630\n",
            "Time taken for 1 epoch 1.015977144241333 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 5 Batch 0 Loss 6072.2100\n",
            "Epoch 5 Loss 4397.2310\n",
            "Time taken for 1 epoch 1.0205028057098389 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 6 Batch 0 Loss 6478.3281\n",
            "Epoch 6 Loss 4316.9766\n",
            "Time taken for 1 epoch 1.0149409770965576 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 7 Batch 0 Loss 5829.6094\n",
            "Epoch 7 Loss 3698.4148\n",
            "Time taken for 1 epoch 1.026313066482544 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 8 Batch 0 Loss 4452.7827\n",
            "Epoch 8 Loss 5657.8945\n",
            "Time taken for 1 epoch 1.0057528018951416 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 9 Batch 0 Loss 5348.3345\n",
            "Epoch 9 Loss 4864.4731\n",
            "Time taken for 1 epoch 1.0138585567474365 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 10 Batch 0 Loss 6620.9868\n",
            "Epoch 10 Loss 5221.0293\n",
            "Time taken for 1 epoch 1.4695374965667725 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 11 Batch 0 Loss 5467.0273\n",
            "Epoch 11 Loss 4811.4272\n",
            "Time taken for 1 epoch 1.0395913124084473 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 12 Batch 0 Loss 6363.7402\n",
            "Epoch 12 Loss 5433.5049\n",
            "Time taken for 1 epoch 1.0146470069885254 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 13 Batch 0 Loss 6875.6943\n",
            "Epoch 13 Loss 5002.8027\n",
            "Time taken for 1 epoch 1.0239102840423584 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 14 Batch 0 Loss 5755.6479\n",
            "Epoch 14 Loss 4278.4648\n",
            "Time taken for 1 epoch 1.0296425819396973 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 15 Batch 0 Loss 6655.2441\n",
            "Epoch 15 Loss 5421.3594\n",
            "Time taken for 1 epoch 1.0277464389801025 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 16 Batch 0 Loss 7262.5454\n",
            "Epoch 16 Loss 7209.0435\n",
            "Time taken for 1 epoch 1.0254697799682617 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 17 Batch 0 Loss 10109.4385\n",
            "Epoch 17 Loss 7758.9248\n",
            "Time taken for 1 epoch 1.0208282470703125 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 18 Batch 0 Loss 10209.9922\n",
            "Epoch 18 Loss 6463.0493\n",
            "Time taken for 1 epoch 1.0123131275177002 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 19 Batch 0 Loss 7430.0103\n",
            "Epoch 19 Loss 5158.7119\n",
            "Time taken for 1 epoch 1.027033805847168 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 20 Batch 0 Loss 6020.1216\n",
            "Epoch 20 Loss 4254.6328\n",
            "Time taken for 1 epoch 1.4887866973876953 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 21 Batch 0 Loss 5943.5415\n",
            "Epoch 21 Loss 3598.0991\n",
            "Time taken for 1 epoch 1.0526964664459229 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 22 Batch 0 Loss 3657.1301\n",
            "Epoch 22 Loss 3297.5938\n",
            "Time taken for 1 epoch 1.0033178329467773 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 23 Batch 0 Loss 4962.3618\n",
            "Epoch 23 Loss 3701.0786\n",
            "Time taken for 1 epoch 1.0275611877441406 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 24 Batch 0 Loss 4656.4165\n",
            "Epoch 24 Loss 2812.8000\n",
            "Time taken for 1 epoch 1.0188298225402832 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 25 Batch 0 Loss 3562.4973\n",
            "Epoch 25 Loss 2349.1841\n",
            "Time taken for 1 epoch 1.021071434020996 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 26 Batch 0 Loss 3481.8960\n",
            "Epoch 26 Loss 2252.1453\n",
            "Time taken for 1 epoch 1.0056202411651611 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 27 Batch 0 Loss 3145.9189\n",
            "Epoch 27 Loss 2300.4351\n",
            "Time taken for 1 epoch 1.0188007354736328 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 28 Batch 0 Loss 2803.2200\n",
            "Epoch 28 Loss 2176.3389\n",
            "Time taken for 1 epoch 1.0169999599456787 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 29 Batch 0 Loss 3571.9587\n",
            "Epoch 29 Loss 9154.8340\n",
            "Time taken for 1 epoch 0.9959347248077393 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 30 Batch 0 Loss 19268.6953\n",
            "Epoch 30 Loss 11080.1055\n",
            "Time taken for 1 epoch 1.5190763473510742 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 31 Batch 0 Loss 15005.2656\n",
            "Epoch 31 Loss 13811.7188\n",
            "Time taken for 1 epoch 1.022719383239746 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 32 Batch 0 Loss 31847.3574\n",
            "Epoch 32 Loss 28199.2910\n",
            "Time taken for 1 epoch 0.9985718727111816 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 33 Batch 0 Loss 37293.4570\n",
            "Epoch 33 Loss 33093.6367\n",
            "Time taken for 1 epoch 1.0296359062194824 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 34 Batch 0 Loss 42697.5508\n",
            "Epoch 34 Loss 37256.6602\n",
            "Time taken for 1 epoch 0.9956760406494141 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 35 Batch 0 Loss 49119.4805\n",
            "Epoch 35 Loss 33273.4727\n",
            "Time taken for 1 epoch 1.0090739727020264 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 36 Batch 0 Loss 38695.6289\n",
            "Epoch 36 Loss 28728.8984\n",
            "Time taken for 1 epoch 1.0127947330474854 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 37 Batch 0 Loss 30192.3848\n",
            "Epoch 37 Loss 23632.6230\n",
            "Time taken for 1 epoch 0.9964663982391357 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 38 Batch 0 Loss 21530.0566\n",
            "Epoch 38 Loss 17833.9805\n",
            "Time taken for 1 epoch 0.9956643581390381 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 39 Batch 0 Loss 22959.3262\n",
            "Epoch 39 Loss 14470.4893\n",
            "Time taken for 1 epoch 1.0166771411895752 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 40 Batch 0 Loss 15171.6406\n",
            "Epoch 40 Loss 12044.2002\n",
            "Time taken for 1 epoch 1.4437227249145508 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 41 Batch 0 Loss 14519.1602\n",
            "Epoch 41 Loss 9364.0430\n",
            "Time taken for 1 epoch 1.0295112133026123 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 42 Batch 0 Loss 10454.3994\n",
            "Epoch 42 Loss 7631.6758\n",
            "Time taken for 1 epoch 1.0027053356170654 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 43 Batch 0 Loss 8225.9307\n",
            "Epoch 43 Loss 6372.5127\n",
            "Time taken for 1 epoch 1.0062217712402344 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 44 Batch 0 Loss 8813.4414\n",
            "Epoch 44 Loss 5429.4849\n",
            "Time taken for 1 epoch 0.9955456256866455 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 45 Batch 0 Loss 6203.4043\n",
            "Epoch 45 Loss 4855.9048\n",
            "Time taken for 1 epoch 1.0237867832183838 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 46 Batch 0 Loss 6239.0928\n",
            "Epoch 46 Loss 4745.1660\n",
            "Time taken for 1 epoch 1.0010261535644531 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 47 Batch 0 Loss 7059.5601\n",
            "Epoch 47 Loss 4219.9912\n",
            "Time taken for 1 epoch 0.9987554550170898 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 48 Batch 0 Loss 4753.2344\n",
            "Epoch 48 Loss 3616.0583\n",
            "Time taken for 1 epoch 0.9874475002288818 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 49 Batch 0 Loss 5250.2705\n",
            "Epoch 49 Loss 3347.7158\n",
            "Time taken for 1 epoch 0.9977927207946777 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 50 Batch 0 Loss 3956.4241\n",
            "Epoch 50 Loss 3039.9634\n",
            "Time taken for 1 epoch 1.4713106155395508 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 51 Batch 0 Loss 4276.7700\n",
            "Epoch 51 Loss 2838.3560\n",
            "Time taken for 1 epoch 1.012007713317871 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 52 Batch 0 Loss 3748.9792\n",
            "Epoch 52 Loss 2781.7117\n",
            "Time taken for 1 epoch 1.0000927448272705 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 53 Batch 0 Loss 3533.8350\n",
            "Epoch 53 Loss 2810.0894\n",
            "Time taken for 1 epoch 0.9929094314575195 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 54 Batch 0 Loss 3684.4028\n",
            "Epoch 54 Loss 3005.5676\n",
            "Time taken for 1 epoch 1.0029335021972656 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 55 Batch 0 Loss 5014.2832\n",
            "Epoch 55 Loss 3082.8779\n",
            "Time taken for 1 epoch 1.0024619102478027 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 56 Batch 0 Loss 4406.0830\n",
            "Epoch 56 Loss 3120.1724\n",
            "Time taken for 1 epoch 0.9860048294067383 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 57 Batch 0 Loss 3524.8176\n",
            "Epoch 57 Loss 3128.9888\n",
            "Time taken for 1 epoch 1.013014316558838 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 58 Batch 0 Loss 4607.7529\n",
            "Epoch 58 Loss 3054.4658\n",
            "Time taken for 1 epoch 1.0036087036132812 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 59 Batch 0 Loss 4473.3696\n",
            "Epoch 59 Loss 2975.6167\n",
            "Time taken for 1 epoch 0.9911093711853027 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 60 Batch 0 Loss 4178.7275\n",
            "Epoch 60 Loss 2944.9534\n",
            "Time taken for 1 epoch 1.5022644996643066 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 61 Batch 0 Loss 4624.4839\n",
            "Epoch 61 Loss 2932.6643\n",
            "Time taken for 1 epoch 1.0175392627716064 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 62 Batch 0 Loss 3505.4294\n",
            "Epoch 62 Loss 2905.3667\n",
            "Time taken for 1 epoch 0.992438793182373 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 63 Batch 0 Loss 3375.7339\n",
            "Epoch 63 Loss 2909.8093\n",
            "Time taken for 1 epoch 1.014880657196045 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 64 Batch 0 Loss 3895.6924\n",
            "Epoch 64 Loss 2820.5530\n",
            "Time taken for 1 epoch 1.0076088905334473 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 65 Batch 0 Loss 3089.8667\n",
            "Epoch 65 Loss 2518.5762\n",
            "Time taken for 1 epoch 1.014803409576416 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 66 Batch 0 Loss 3093.8584\n",
            "Epoch 66 Loss 2256.8479\n",
            "Time taken for 1 epoch 1.005141258239746 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 67 Batch 0 Loss 2943.9727\n",
            "Epoch 67 Loss 2388.2458\n",
            "Time taken for 1 epoch 1.0099270343780518 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 68 Batch 0 Loss 2754.4749\n",
            "Epoch 68 Loss 2215.0864\n",
            "Time taken for 1 epoch 1.0101606845855713 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 69 Batch 0 Loss 3385.2971\n",
            "Epoch 69 Loss 2076.4861\n",
            "Time taken for 1 epoch 1.019796371459961 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 70 Batch 0 Loss 3218.8557\n",
            "Epoch 70 Loss 3424.5295\n",
            "Time taken for 1 epoch 1.4869284629821777 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 71 Batch 0 Loss 3842.0105\n",
            "Epoch 71 Loss 3321.8372\n",
            "Time taken for 1 epoch 1.028656005859375 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 72 Batch 0 Loss 4754.2935\n",
            "Epoch 72 Loss 3832.1035\n",
            "Time taken for 1 epoch 1.0149364471435547 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 73 Batch 0 Loss 5723.0332\n",
            "Epoch 73 Loss 3626.8159\n",
            "Time taken for 1 epoch 1.012573480606079 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 74 Batch 0 Loss 4632.7129\n",
            "Epoch 74 Loss 3367.7310\n",
            "Time taken for 1 epoch 1.0017309188842773 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 75 Batch 0 Loss 4736.4165\n",
            "Epoch 75 Loss 3171.6016\n",
            "Time taken for 1 epoch 1.015681266784668 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 76 Batch 0 Loss 4416.4590\n",
            "Epoch 76 Loss 3105.7126\n",
            "Time taken for 1 epoch 1.0222728252410889 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 77 Batch 0 Loss 5225.3506\n",
            "Epoch 77 Loss 3210.7769\n",
            "Time taken for 1 epoch 1.0123012065887451 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 78 Batch 0 Loss 2972.4146\n",
            "Epoch 78 Loss 2503.3379\n",
            "Time taken for 1 epoch 0.9987156391143799 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 79 Batch 0 Loss 2976.8875\n",
            "Epoch 79 Loss 2231.9187\n",
            "Time taken for 1 epoch 0.998849630355835 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 80 Batch 0 Loss 3354.7563\n",
            "Epoch 80 Loss 2114.5198\n",
            "Time taken for 1 epoch 1.463789701461792 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 81 Batch 0 Loss 2187.5784\n",
            "Epoch 81 Loss 2155.0825\n",
            "Time taken for 1 epoch 1.042670488357544 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 82 Batch 0 Loss 3382.8025\n",
            "Epoch 82 Loss 2444.3367\n",
            "Time taken for 1 epoch 1.0210258960723877 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 83 Batch 0 Loss 3321.2012\n",
            "Epoch 83 Loss 2376.0159\n",
            "Time taken for 1 epoch 1.0041229724884033 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 84 Batch 0 Loss 3450.5239\n",
            "Epoch 84 Loss 2305.8601\n",
            "Time taken for 1 epoch 1.0096874237060547 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 85 Batch 0 Loss 2731.3604\n",
            "Epoch 85 Loss 2169.4717\n",
            "Time taken for 1 epoch 1.0046138763427734 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 86 Batch 0 Loss 2919.5432\n",
            "Epoch 86 Loss 2119.0454\n",
            "Time taken for 1 epoch 1.0161588191986084 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 87 Batch 0 Loss 2594.7532\n",
            "Epoch 87 Loss 2086.5847\n",
            "Time taken for 1 epoch 0.9926519393920898 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 88 Batch 0 Loss 2653.6367\n",
            "Epoch 88 Loss 2118.7771\n",
            "Time taken for 1 epoch 1.0070593357086182 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 89 Batch 0 Loss 2976.7415\n",
            "Epoch 89 Loss 2001.8955\n",
            "Time taken for 1 epoch 1.0038795471191406 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 90 Batch 0 Loss 2700.7280\n",
            "Epoch 90 Loss 1886.4209\n",
            "Time taken for 1 epoch 1.4830775260925293 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 91 Batch 0 Loss 2483.1755\n",
            "Epoch 91 Loss 1908.4160\n",
            "Time taken for 1 epoch 1.027895450592041 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 92 Batch 0 Loss 2106.5356\n",
            "Epoch 92 Loss 1978.1042\n",
            "Time taken for 1 epoch 1.0088131427764893 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 93 Batch 0 Loss 2313.6938\n",
            "Epoch 93 Loss 2013.2499\n",
            "Time taken for 1 epoch 1.0068461894989014 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 94 Batch 0 Loss 3859.7478\n",
            "Epoch 94 Loss 2028.8264\n",
            "Time taken for 1 epoch 1.0138447284698486 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 95 Batch 0 Loss 2843.6597\n",
            "Epoch 95 Loss 1949.7170\n",
            "Time taken for 1 epoch 0.9993250370025635 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 96 Batch 0 Loss 2599.6133\n",
            "Epoch 96 Loss 1849.4164\n",
            "Time taken for 1 epoch 1.0111677646636963 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 97 Batch 0 Loss 2379.8354\n",
            "Epoch 97 Loss 1792.7827\n",
            "Time taken for 1 epoch 1.0103740692138672 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 98 Batch 0 Loss 2088.8064\n",
            "Epoch 98 Loss 1755.8671\n",
            "Time taken for 1 epoch 1.009448528289795 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 99 Batch 0 Loss 1828.5137\n",
            "Epoch 99 Loss 1712.3547\n",
            "Time taken for 1 epoch 1.0134527683258057 sec\n",
            "\n",
            "(64, 1024) (64, 1024)\n",
            "Epoch 100 Batch 0 Loss 1992.2352\n",
            "Epoch 100 Loss 1545.3429\n",
            "Time taken for 1 epoch 1.4577667713165283 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkua2AlCWfeC"
      },
      "source": [
        "def evaluate_sentence(sentence):\r\n",
        "  # preprocess the sentence and turn into tensor after splitting words.\r\n",
        "  sentence = dataset_creator.preprocess_sentence(sentence)\r\n",
        "  print(f\"Input sentence: {sentence}\")\r\n",
        "  # print(inp_lang.word_index)\r\n",
        "\r\n",
        "  # if word is in tokenizer, then use it, otherwise use 1 for OOV.\r\n",
        "  inputs = [inp_lang.word_index[i] if i in inp_lang.word_index else 1 for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                          maxlen=max_length_input,\r\n",
        "                                                          padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "  inference_batch_size = inputs.shape[0]\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  # send to encoder to get a representation.\r\n",
        "  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\r\n",
        "  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\r\n",
        "\r\n",
        "  dec_h = enc_h\r\n",
        "  dec_c = enc_c\r\n",
        "\r\n",
        "  start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<start>'])\r\n",
        "  end_token = targ_lang.word_index['<end>']\r\n",
        "\r\n",
        "  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\r\n",
        "\r\n",
        "  # Instantiate BasicDecoder object\r\n",
        "  decoder_instance = tfa.seq2seq.BasicDecoder(\r\n",
        "      cell=decoder.rnn_cell, \r\n",
        "      sampler=greedy_sampler, \r\n",
        "      output_layer=decoder.fc)\r\n",
        "  # Setup Memory in decoder stack\r\n",
        "  decoder.attention_mechanism.setup_memory(enc_out)\r\n",
        "\r\n",
        "  # set decoder_initial_state\r\n",
        "  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\r\n",
        "\r\n",
        "  ### Since the BasicDecoder wraps around Decoder's rnn cell only, you have to ensure that the inputs to BasicDecoder \r\n",
        "  ### decoding step is output of embedding layer. tfa.seq2seq.GreedyEmbeddingSampler() takes care of this. \r\n",
        "  ### You only need to get the weights of embedding layer, which can be done by decoder.embedding.variables[0] and pass this callabble to BasicDecoder's call() function\r\n",
        "\r\n",
        "  decoder_embedding_matrix = decoder.embedding.variables[0]\r\n",
        "\r\n",
        "  outputs, _, _ = decoder_instance(\r\n",
        "      decoder_embedding_matrix, \r\n",
        "      start_tokens = start_tokens, \r\n",
        "      end_token= end_token, \r\n",
        "      initial_state=decoder_initial_state)\r\n",
        "  return outputs.sample_id.numpy()\r\n",
        "\r\n",
        "def translate(sentence):\r\n",
        "  result = evaluate_sentence(sentence)\r\n",
        "  print(result)\r\n",
        "  result = targ_lang.sequences_to_texts(result)\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DVb-O8WadGs",
        "outputId": "15332ca2-569a-41b8-93f4-a4712c945a2c"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3600477400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zlq4erwam2D",
        "outputId": "96305e4f-6c91-4d78-e5a5-37e9b9ac0ce5"
      },
      "source": [
        "# EN: action taken on parliament's resolutions see minutes\r\n",
        "translate(u'ACTION TAKE ON PARLIAMENT X-POSS RESOLUTION SEE MINUTE')\r\n",
        "\r\n",
        "# EN:  the results speak for themselves .\r\n",
        "translate(u'RESULT SPEAK FOR X-MSELVES .')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sentence: <start> action take on parliament x-poss resolution see minute <end>\n",
            "[[ 23 767   3]]\n",
            "Input: ACTION TAKE ON PARLIAMENT X-POSS RESOLUTION SEE MINUTE\n",
            "Predicted translation: ['document pirker <end>']\n",
            "Input sentence: <start> result speak for x-mselves . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul6fu1zq_xjz"
      },
      "source": [
        "## Throw Aaway Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5siCy6i7IO"
      },
      "source": [
        "total_words = defaultdict(lambda: 0)\r\n",
        "regex_split = \"\\s+|,|\\.|\\?\"\r\n",
        "line_count = 0\r\n",
        "for line in f:\r\n",
        "  line_count += 1\r\n",
        "  words = re.split(regex_split, line.strip())\r\n",
        "  for word in words:\r\n",
        "    if word != \"\":\r\n",
        "      total_words[word]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxIf6wdoV1B"
      },
      "source": [
        "print(f\"There are {line_count} lines.\")\r\n",
        "print(f\"There are {len(total_words)} words.\")\r\n",
        "\r\n",
        "print(\"Getting descending list of common words.\")\r\n",
        "sorted_dict =  dict( sorted(total_words.items(),\r\n",
        "                           key=lambda item: item[1],\r\n",
        "                           reverse=True))\r\n",
        "\r\n",
        "sorted_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cManW-VaISjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}